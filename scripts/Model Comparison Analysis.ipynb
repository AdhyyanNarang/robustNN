{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0926 22:33:07.157025 4406191552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import os, random, time, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "sys.path.append('../')\n",
    "sys.path.append('../utils/')\n",
    "import feedforward_robust as ffr\n",
    "import ipdb\n",
    "from utils.mnist_corruption import *\n",
    "from utils.utils_models import *\n",
    "from utils.utils_analysis import *\n",
    "from utils.utils_feedforward import *\n",
    "\n",
    "#Read the counter\n",
    "ctr_file = \"counter.txt\"\n",
    "f = open(ctr_file, 'r')\n",
    "counter = f.readline()\n",
    "f.close()\n",
    "\n",
    "counter = 1 + int(counter)\n",
    "f = open(ctr_file,'w')\n",
    "f.write('{}'.format(counter))\n",
    "f.close()\n",
    "logfile = \"logs/results_\" + str(counter) + \".log\"\n",
    "\n",
    "logger = logging.getLogger(\"robustness\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup - Dataset stuff\n",
    "dataset, input_shape, num_classes = get_dataset()\n",
    "x_train_flat, y_train = dataset[0] \n",
    "x_test_flat, y_test = dataset[1] \n",
    "hidden_sizes = [32,32,32,32,32,32,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_list = [\"hybrid\", \"model_non_robust\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_2d = [vec.reshape((28,28)) for vec in x_test_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "\n",
    "ax1.plot(range(10), range(10))\n",
    "ax2.plot(range(10), range(10))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out different corruptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random trying out stuff\n",
    "x_test_gaussian_blurred = gaussian_blurring(x_test_2d, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_rotated = rotate(x_test_2d, angle = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15659a278>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_gaussian_blurred[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Training Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['eps_train'] = 0.1\n",
    "config['eps_test'] = 0.1\n",
    "config['tensorboard_dir'] = \"tb/\"\n",
    "config['weights_dir'] = \"weights/\"\n",
    "\n",
    "config['load_counter'] = 222\n",
    "config['write_counter'] = counter\n",
    "config['sigma'] = tf.nn.relu\n",
    "config['epochs'] = 10\n",
    "config['reg'] = 0.0\n",
    "config['lr'] = 3e-4\n",
    "\n",
    "config['scope_name'] = \"model_non_robust\"\n",
    "config['should_load'] = False\n",
    "config['logger'] = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0927 00:37:10.213084 4406191552 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0927 00:37:10.221186 4406191552 feedforward_robust.py:38] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0927 00:37:10.397358 4406191552 feedforward_robust.py:42] Created layers and tensor for logits\n",
      "Added loss computation to the graph\n",
      "I0927 00:37:10.425125 4406191552 feedforward_robust.py:47] Added loss computation to the graph\n",
      "Added accuracy computation to the graph\n",
      "I0927 00:37:10.432898 4406191552 feedforward_robust.py:51] Added accuracy computation to the graph\n",
      "Model graph was created\n",
      "I0927 00:37:10.436273 4406191552 feedforward_robust.py:54] Model graph was created\n",
      "Created model successfully. Now going to load weights\n",
      "I0927 00:37:10.443347 4406191552 utils_models.py:48] Created model successfully. Now going to load weights\n",
      "Epoch: 0001    cost: 1.157836200 \n",
      "I0927 00:37:15.388103 4406191552 feedforward_robust.py:417] Epoch: 0001    cost: 1.157836200 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:37:15.391294 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0002    cost: 0.856963629 \n",
      "I0927 00:37:18.266909 4406191552 feedforward_robust.py:417] Epoch: 0002    cost: 0.856963629 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:18.269743 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0003    cost: 0.780252184 \n",
      "I0927 00:37:20.675577 4406191552 feedforward_robust.py:417] Epoch: 0003    cost: 0.780252184 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:20.676762 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0004    cost: 0.731408141 \n",
      "I0927 00:37:23.020517 4406191552 feedforward_robust.py:417] Epoch: 0004    cost: 0.731408141 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:23.021573 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0005    cost: 0.700448618 \n",
      "I0927 00:37:25.147207 4406191552 feedforward_robust.py:417] Epoch: 0005    cost: 0.700448618 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:37:25.148342 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0006    cost: 0.680248830 \n",
      "I0927 00:37:27.232132 4406191552 feedforward_robust.py:417] Epoch: 0006    cost: 0.680248830 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:37:27.233347 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0007    cost: 0.666170643 \n",
      "I0927 00:37:29.280189 4406191552 feedforward_robust.py:417] Epoch: 0007    cost: 0.666170643 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:29.281755 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0008    cost: 0.646288216 \n",
      "I0927 00:37:31.376060 4406191552 feedforward_robust.py:417] Epoch: 0008    cost: 0.646288216 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:31.377253 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0009    cost: 0.637174134 \n",
      "I0927 00:37:33.591212 4406191552 feedforward_robust.py:417] Epoch: 0009    cost: 0.637174134 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:33.592857 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0010    cost: 0.635151651 \n",
      "I0927 00:37:35.668138 4406191552 feedforward_robust.py:417] Epoch: 0010    cost: 0.635151651 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:37:35.669552 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0011    cost: 0.626834969 \n",
      "I0927 00:37:38.063985 4406191552 feedforward_robust.py:417] Epoch: 0011    cost: 0.626834969 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:38.065403 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0012    cost: 0.626554361 \n",
      "I0927 00:37:41.200069 4406191552 feedforward_robust.py:417] Epoch: 0012    cost: 0.626554361 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:41.201632 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0013    cost: 0.619516964 \n",
      "I0927 00:37:43.651256 4406191552 feedforward_robust.py:417] Epoch: 0013    cost: 0.619516964 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:37:43.652670 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0014    cost: 0.615480410 \n",
      "I0927 00:37:45.954502 4406191552 feedforward_robust.py:417] Epoch: 0014    cost: 0.615480410 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:45.956320 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0015    cost: 0.614889591 \n",
      "I0927 00:37:48.265658 4406191552 feedforward_robust.py:417] Epoch: 0015    cost: 0.614889591 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:48.266909 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0016    cost: 0.611852853 \n",
      "I0927 00:37:50.395066 4406191552 feedforward_robust.py:417] Epoch: 0016    cost: 0.611852853 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:37:50.396804 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0017    cost: 0.610766900 \n",
      "I0927 00:37:52.680524 4406191552 feedforward_robust.py:417] Epoch: 0017    cost: 0.610766900 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:52.681935 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0018    cost: 0.609415423 \n",
      "I0927 00:37:54.904914 4406191552 feedforward_robust.py:417] Epoch: 0018    cost: 0.609415423 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:37:54.906245 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0019    cost: 0.607187479 \n",
      "I0927 00:37:57.092416 4406191552 feedforward_robust.py:417] Epoch: 0019    cost: 0.607187479 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:57.093703 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0020    cost: 0.601883771 \n",
      "I0927 00:37:59.283622 4406191552 feedforward_robust.py:417] Epoch: 0020    cost: 0.601883771 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:37:59.284909 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0021    cost: 0.598662039 \n",
      "I0927 00:38:01.492444 4406191552 feedforward_robust.py:417] Epoch: 0021    cost: 0.598662039 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:01.493914 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0022    cost: 0.595640933 \n",
      "I0927 00:38:03.798958 4406191552 feedforward_robust.py:417] Epoch: 0022    cost: 0.595640933 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:03.800848 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0023    cost: 0.597138942 \n",
      "I0927 00:38:06.110725 4406191552 feedforward_robust.py:417] Epoch: 0023    cost: 0.597138942 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:38:06.111961 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0024    cost: 0.590210507 \n",
      "I0927 00:38:08.454672 4406191552 feedforward_robust.py:417] Epoch: 0024    cost: 0.590210507 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:08.456057 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0025    cost: 0.590300665 \n",
      "I0927 00:38:10.566325 4406191552 feedforward_robust.py:417] Epoch: 0025    cost: 0.590300665 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:10.567989 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0026    cost: 0.589231377 \n",
      "I0927 00:38:12.713948 4406191552 feedforward_robust.py:417] Epoch: 0026    cost: 0.589231377 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:38:12.715265 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0027    cost: 0.589664057 \n",
      "I0927 00:38:14.867174 4406191552 feedforward_robust.py:417] Epoch: 0027    cost: 0.589664057 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:14.868458 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0028    cost: 0.586756384 \n",
      "I0927 00:38:17.025616 4406191552 feedforward_robust.py:417] Epoch: 0028    cost: 0.586756384 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:17.026746 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0029    cost: 0.583052609 \n",
      "I0927 00:38:19.220080 4406191552 feedforward_robust.py:417] Epoch: 0029    cost: 0.583052609 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:19.221306 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0030    cost: 0.587939417 \n",
      "I0927 00:38:21.450984 4406191552 feedforward_robust.py:417] Epoch: 0030    cost: 0.587939417 \n",
      "Accuracy on batch: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0927 00:38:21.452136 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0031    cost: 0.581145068 \n",
      "I0927 00:38:23.725812 4406191552 feedforward_robust.py:417] Epoch: 0031    cost: 0.581145068 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:38:23.727741 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0032    cost: 0.577700119 \n",
      "I0927 00:38:26.315976 4406191552 feedforward_robust.py:417] Epoch: 0032    cost: 0.577700119 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:26.317246 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0033    cost: 0.574506921 \n",
      "I0927 00:38:28.854799 4406191552 feedforward_robust.py:417] Epoch: 0033    cost: 0.574506921 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:28.856104 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0034    cost: 0.577398122 \n",
      "I0927 00:38:31.059686 4406191552 feedforward_robust.py:417] Epoch: 0034    cost: 0.577398122 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:31.060926 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0035    cost: 0.571710415 \n",
      "I0927 00:38:33.137794 4406191552 feedforward_robust.py:417] Epoch: 0035    cost: 0.571710415 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:33.139670 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0036    cost: 0.574912621 \n",
      "I0927 00:38:35.236824 4406191552 feedforward_robust.py:417] Epoch: 0036    cost: 0.574912621 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:35.238029 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0037    cost: 0.573574282 \n",
      "I0927 00:38:37.451983 4406191552 feedforward_robust.py:417] Epoch: 0037    cost: 0.573574282 \n",
      "Accuracy on batch: 0.906250\n",
      "I0927 00:38:37.453509 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.906250\n",
      "Epoch: 0038    cost: 0.571847345 \n",
      "I0927 00:38:39.845222 4406191552 feedforward_robust.py:417] Epoch: 0038    cost: 0.571847345 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:39.846969 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0039    cost: 0.572558906 \n",
      "I0927 00:38:42.129433 4406191552 feedforward_robust.py:417] Epoch: 0039    cost: 0.572558906 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:42.130917 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0040    cost: 0.573817437 \n",
      "I0927 00:38:44.307470 4406191552 feedforward_robust.py:417] Epoch: 0040    cost: 0.573817437 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:38:44.308869 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0041    cost: 0.571568262 \n",
      "I0927 00:38:46.465594 4406191552 feedforward_robust.py:417] Epoch: 0041    cost: 0.571568262 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:38:46.466943 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0042    cost: 0.566448591 \n",
      "I0927 00:38:48.612061 4406191552 feedforward_robust.py:417] Epoch: 0042    cost: 0.566448591 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:48.613478 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0043    cost: 0.568484534 \n",
      "I0927 00:38:50.808962 4406191552 feedforward_robust.py:417] Epoch: 0043    cost: 0.568484534 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:38:50.810795 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0044    cost: 0.568525366 \n",
      "I0927 00:38:52.937160 4406191552 feedforward_robust.py:417] Epoch: 0044    cost: 0.568525366 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:52.938767 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0045    cost: 0.563991537 \n",
      "I0927 00:38:54.981981 4406191552 feedforward_robust.py:417] Epoch: 0045    cost: 0.563991537 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:38:54.983571 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0046    cost: 0.566957776 \n",
      "I0927 00:38:57.267695 4406191552 feedforward_robust.py:417] Epoch: 0046    cost: 0.566957776 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:57.268933 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0047    cost: 0.566224579 \n",
      "I0927 00:38:59.420407 4406191552 feedforward_robust.py:417] Epoch: 0047    cost: 0.566224579 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:38:59.421587 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Epoch: 0048    cost: 0.567747226 \n",
      "I0927 00:39:02.330036 4406191552 feedforward_robust.py:417] Epoch: 0048    cost: 0.567747226 \n",
      "Accuracy on batch: 0.937500\n",
      "I0927 00:39:02.339110 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.937500\n",
      "Epoch: 0049    cost: 0.566111893 \n",
      "I0927 00:39:04.994369 4406191552 feedforward_robust.py:417] Epoch: 0049    cost: 0.566111893 \n",
      "Accuracy on batch: 1.000000\n",
      "I0927 00:39:04.996195 4406191552 feedforward_robust.py:418] Accuracy on batch: 1.000000\n",
      "Epoch: 0050    cost: 0.566698418 \n",
      "I0927 00:39:07.260385 4406191552 feedforward_robust.py:417] Epoch: 0050    cost: 0.566698418 \n",
      "Accuracy on batch: 0.968750\n",
      "I0927 00:39:07.262137 4406191552 feedforward_robust.py:418] Accuracy on batch: 0.968750\n",
      "Optimization Finished!\n",
      "I0927 00:39:07.264340 4406191552 feedforward_robust.py:419] Optimization Finished!\n",
      "Final Train Loss 0.316529\n",
      "I0927 00:39:07.570199 4406191552 feedforward_robust.py:427] Final Train Loss 0.316529\n",
      "Final Train Accuracy 0.907650:\n",
      "I0927 00:39:07.571358 4406191552 feedforward_robust.py:428] Final Train Accuracy 0.907650:\n",
      "Model was trained on benign data\n",
      "I0927 00:39:07.574316 4406191552 feedforward_robust.py:446] Model was trained on benign data\n",
      "Saved model at weights/model_367.ckpt\n",
      "I0927 00:39:07.807751 4406191552 utils_models.py:65] Saved model at weights/model_367.ckpt\n",
      "Model was evaluated on benign data\n",
      "I0927 00:39:07.867119 4406191552 feedforward_robust.py:359] Model was evaluated on benign data\n",
      "----Regular test accuracy and loss ----\n",
      "I0927 00:39:07.928981 4406191552 utils_models.py:70] ----Regular test accuracy and loss ----\n",
      "(0.31516236, 0.9102)\n",
      "I0927 00:39:07.932032 4406191552 utils_models.py:71] (0.31516236, 0.9102)\n",
      "Model was evaluated on benign data\n",
      "I0927 00:39:07.957489 4406191552 feedforward_robust.py:359] Model was evaluated on benign data\n",
      "----Regular test accuracy and loss ----\n",
      "I0927 00:39:07.960065 4406191552 utils_models.py:74] ----Regular test accuracy and loss ----\n",
      "(0.31516236, 0.9102)\n",
      "I0927 00:39:07.963913 4406191552 utils_models.py:75] (0.31516236, 0.9102)\n",
      "Model is being evaluated on FGSM data\n",
      "I0927 00:39:08.199053 4406191552 feedforward_robust.py:366] Model is being evaluated on FGSM data\n",
      "----FGSM test accuracy and loss ----\n",
      "I0927 00:39:08.214723 4406191552 utils_models.py:78] ----FGSM test accuracy and loss ----\n",
      "(3.228799, 0.3262)\n",
      "I0927 00:39:08.216186 4406191552 utils_models.py:79] (3.228799, 0.3262)\n"
     ]
    }
   ],
   "source": [
    "#model_hybrid, sess_hybrid, = regular_training(config)\n",
    "model, sess, path = l1_reg_model_train(counter, logger, 0.0009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-312382290f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['eps_train'] = 0.1\n",
    "config['eps_test'] = 0.1\n",
    "config['tensorboard_dir'] = \"tb/\"\n",
    "config['weights_dir'] = \"weights/\"\n",
    "\n",
    "config['load_counter_robust'] = 280\n",
    "config['load_counter_non_robust'] = 282\n",
    "config['should_slash'] = False\n",
    "config['slash_factor'] = 0.70\n",
    "\n",
    "config['sigma'] = tf.nn.relu\n",
    "\n",
    "config['scope_name'] = \"hybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid, sess_hybrid = hybrid_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_test_hybrid = model_hybrid.get_dphi_dx(sess_hybrid, x_test_flat)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(dphi_dx_test_hybrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpred_dx_test_hybrid = model_hybrid.get_pred_dx(sess_hybrid, x_test_flat)[0]\n",
    "np.mean(np.abs(dpred_dx_test_hybrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['eps_train'] = 0.1\n",
    "config['eps_test'] = 0.1\n",
    "config['tensorboard_dir'] = \"tb/\"\n",
    "config['weights_dir'] = \"weights/\"\n",
    "\n",
    "config['load_counter'] = 222\n",
    "config['sigma'] = tf.nn.relu\n",
    "\n",
    "config['scope_name'] = \"model_non_robust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['scope_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_non_robust, sess_non_robust = regular_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(config['scope_name']) as scope:\n",
    "    weights_non_robust = model_non_robust.get_weights_np(sess_non_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original without regularization\n",
    "sing_vals = []\n",
    "for (idx, weight_matrix) in enumerate(weights_non_robust):\n",
    "        sig = plot_singular_values(weight_matrix, idx, \"Non robust model\")\n",
    "        sing_vals.append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular points\n",
    "acts = model_non_robust.get_activation(sess_non_robust, x_test_flat)\n",
    "diff, diff_norm = activation_distance(acts)\n",
    "\n",
    "#Adversarial points\n",
    "x_test_flat_adv = model_non_robust.fgsm_np(sess_non_robust, x_test_flat, y_test, config['eps_test'])\n",
    "acts_adv = model_non_robust.get_activation(sess_non_robust, x_test_flat_adv)\n",
    "diff_adv, diff_norm_adv = activation_distance(acts_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_test = model_non_robust.get_dphi_dx(sess_non_robust, x_test_flat)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_test_non_robust = dphi_dx_test\n",
    "np.mean(np.abs(dphi_dx_test_non_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpred_dx_test_non_robust = model_non_robust.get_pred_dx(sess_non_robust, x_test_flat)[0]\n",
    "np.mean(np.abs(dpred_dx_test_non_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(config['scope_name'], reuse = tf.AUTO_REUSE) as scope:\n",
    "    x_test_feat_pert = model_non_robust.attack_featurization_space(sess_non_robust, x_test_flat, y_test, 1.0, 0.1, 200)\n",
    "    loss_feat_adv, acc_feat_adv = model_non_robust.evaluate_from_featurizations(sess_non_robust, x_test_feat_pert, y_test)\n",
    "    print(loss_feat_adv, acc_feat_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images_fgsm = model_non_robust.fgsm_np(sess_non_robust, x_test_flat, y_test, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = adv_images_fgsm[0]\n",
    "two_d = test_image.reshape((28,28))\n",
    "plt.imshow(two_d, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_image = adv_images_pgd[0]\n",
    "two_d = test_image.reshape((28,28))\n",
    "plt.imshow(two_d, cmap = plt.cm.binary)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace regularization for first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "config = {}\n",
    "config['eps_train'] = 0.1\n",
    "config['eps_test'] = 0.1\n",
    "config['tensorboard_dir'] = \"tb/\"\n",
    "config['weights_dir'] = \"weights/\"\n",
    "\n",
    "config['load_counter'] = 121\n",
    "config['sigma'] = tf.nn.relu\n",
    "\n",
    "config['scope_name'] = \"model_non_robust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['scope_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model, sess_reg = regular_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(config['scope_name']) as scope:\n",
    "    weights = reg_model.get_weights_np(sess_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With regularization\n",
    "sing_vals_reg = []\n",
    "for (idx, weight_matrix) in enumerate(weights):\n",
    "        sig = plot_singular_values(weight_matrix, idx, \"First layer penalized\")\n",
    "        sing_vals_reg.append(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation** This is pretty interesting. When you penalize the singular values of the first layer, all the other layers start increasing to compensate - I'm guessing to keep the expressiveness high. Probably, if we penalize all the singular values, it may not learn anything?\n",
    "\n",
    "So we still have not suceeded at replicating the singular value spectrum of the robust model - so it is difficult to conclude whether the singular value spectrum is a determinant of adversarial robustness or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With regularization - first layer\n",
    "sing_vals_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular points\n",
    "acts = reg_model.get_activation(sess_reg, x_test_flat)\n",
    "diff, diff_norm = activation_distance(acts)\n",
    "\n",
    "#Adversarial points\n",
    "x_test_flat_adv = reg_model.fgsm_np(sess_reg, x_test_flat, y_test, config['eps_test'])\n",
    "acts_adv = reg_model.get_activation(sess_reg, x_test_flat_adv)\n",
    "diff_adv, diff_norm_adv = activation_distance(acts_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_robust_first_reg = reg_model.get_dphi_dx(sess_reg, x_test_flat)\n",
    "np.mean(np.abs(dphi_dx_robust_first_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpred_dx_robust_first_reg = reg_model.get_pred_dx(sess_reg, x_test_flat)\n",
    "np.mean(np.abs(dpred_dx_robust_first_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace regularization for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "config['eps_train'] = 0.1\n",
    "config['eps_test'] = 0.1\n",
    "config['tensorboard_dir'] = \"tb/\"\n",
    "config['weights_dir'] = \"weights/\"\n",
    "config['load_counter'] = 126\n",
    "config['sigma'] = tf.nn.relu\n",
    "config['scope_name'] = \"model_non_robust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_reg, sess_all_reg = regular_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(config['scope_name']) as scope:\n",
    "    weights = model_all_reg.get_weights_np(sess_all_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With regularization\n",
    "sing_vals_all = []\n",
    "for (idx, weight_matrix) in enumerate(weights):\n",
    "        sig = plot_singular_values(weight_matrix, idx, \"all layers penalized\")\n",
    "        sing_vals_all.append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular points\n",
    "acts = model_all_reg.get_activation(sess_all_reg, x_test_flat)\n",
    "diff, diff_norm = activation_distance(acts)\n",
    "\n",
    "#Adversarial points\n",
    "x_test_flat_adv = model_all_reg.fgsm_np(sess_all_reg, x_test_flat, y_test, config['eps_test'])\n",
    "acts_adv = model_all_reg.get_activation(sess_all_reg, x_test_flat_adv)\n",
    "diff_adv, diff_norm_adv = activation_distance(acts_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_robust_all_reg = reg_model.get_dphi_dx(sess_all_reg, x_test_flat)\n",
    "np.mean(np.abs(dphi_dx_robust_all_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpred_dx_robust_all_reg = reg_model.get_pred_dx(sess_all_reg, x_test_flat)\n",
    "np.mean(np.abs(dpred_dx_robust_all_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "config['eps_train'] = 0.1\n",
    "config['eps_test'] = 0.1\n",
    "config['tensorboard_dir'] = \"tb/\"\n",
    "config['weights_dir'] = \"weights/\"\n",
    "config['load_counter'] = 280\n",
    "config['sigma'] = tf.nn.relu\n",
    "config['scope_name'] = \"model_robust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rob, sess_rob = adversarial_training(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(config['scope_name']) as scope:\n",
    "    weights_robust = model_rob.get_weights_np(sess_rob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals_robust = []\n",
    "for (idx, weight_matrix) in enumerate(weights_robust):\n",
    "    sig = plot_singular_values(weight_matrix, idx, \"FGSM adversarially trained model\")\n",
    "    sing_vals_robust.append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dx_robust = model_rob.get_dphi_dx(sess_rob, x_test_flat)\n",
    "np.mean(np.abs(dphi_dx_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpred_dx_robust = model_rob.get_pred_dx(sess_rob, x_test_flat)\n",
    "np.mean(np.abs(dpred_dx_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals_robust[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals_robust[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals_robust[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_vals_robust[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular points\n",
    "acts = model_rob.get_activation(sess_rob, x_test_flat)\n",
    "diff, diff_norm = activation_distance(acts)\n",
    "\n",
    "#Adversarial points\n",
    "x_test_flat_adv = model_rob.fgsm_np(sess_rob, x_test_flat, y_test, config['eps_test'])\n",
    "acts_adv = model_rob.get_activation(sess_rob, x_test_flat_adv)\n",
    "diff_adv, diff_norm_adv = activation_distance(acts_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_non_robust, model_all_reg, model_rob, model_hybrid, reg_model]\n",
    "sess_list = [sess_non_robust, sess_all_reg, sess_rob, sess_hybrid, sess_reg]\n",
    "scope_list = [\"model_non_robust\", \"model_non_robust\", \"model_robust\", \"hybrid\", \"model_non_robust\"]\n",
    "legend_list = ['non robust', 'all layers trace reg', 'robust', 'hybrid', 'first layer trace reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dist_plot_all_models(model_list, sess_list, scope_list, legend_list, order = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dist_plot_all_models(model_list, sess_list, scope_list, legend_list, order = float(\"inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_non_robust, model_all_reg, model_rob, model_hybrid, reg_model]\n",
    "sess_list = [sess_non_robust, sess_all_reg, sess_rob, sess_hybrid, sess_reg]\n",
    "scope_list = [\"model_non_robust\", \"model_non_robust\", \"model_robust\", \"hybrid\", \"model_non_robust\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_evals, adv_evals, margins, dphi_dxs = get_stats_all_models(model_list, sess_list, scope_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_non_robust, model_all_reg, model_rob, model_hybrid, reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dphi_dxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['non robust', 'Sing val all', 'fgsm train', 'hybrid', 'sing val first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_evals_np = np.array(adv_evals)\n",
    "acc_adv = adv_evals_np[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.arange(len(labels))  # the label locations\n",
    "width = 0.60  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, dphi_dxs, width, label='dphi_dx')\n",
    "rects2 = ax.bar(x + width/2, margins, width, label='margin')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Margins/ Gradient means')\n",
    "ax.set_title('Margins and gradient for diferent models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "print(adv_evals_np[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.arange(len(labels))  # the label locations\n",
    "width = 0.60  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, dphi_dxs, width, label='dphi_dx')\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Gradient means')\n",
    "ax.set_ylim((0, 1.1))\n",
    "ax.set_title('Margins and gradient for diferent models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2 = ax.twinx()\n",
    "rects2 = ax2.bar(x + width/2, margins, width, label='margin', color = color)\n",
    "ax2.set_ylabel('Margins')\n",
    "ax2.set_ylim((0, 0.40))\n",
    "#ax.set_xticks(x)\n",
    "#ax.set_xticklabels(labels)\n",
    "#ax2.legend(legend_loc = (1.0, 0.8))\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for (idx, rect) in enumerate(rects1):\n",
    "        height = rect.get_height()\n",
    "        height_2 = rects2[idx].get_height() * (1.0/0.37)\n",
    "        height = max(height, height_2)\n",
    "        ax.annotate('{:0.3f}'.format(acc_adv[idx]),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()\n",
    "print(adv_evals_np[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_non_robust, model_all_reg, model_rob, model_hybrid, reg_model]\n",
    "sess_list = [sess_non_robust, sess_all_reg, sess_rob, sess_hybrid, sess_reg]\n",
    "eps_list = [0, 0.02, 0.05, 0.1, 0.2, 0.3]\n",
    "scope_list = [\"model_non_robust\", \"model_non_robust\", \"model_robust\", \"hybrid\", \"model_non_robust\"]\n",
    "legend_list = ['non_robust', 'all layers trace reg', 'robust', 'hybrid', 'first layer trace reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_plot_acc_vs_eps(model_list, sess_list, eps_list, legend_list, scope_list, pgd = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_non_robust, model_all_reg, model_rob, model_hybrid, reg_model]\n",
    "sess_list = [sess_non_robust, sess_all_reg, sess_rob, sess_hybrid, sess_reg]\n",
    "eps_list = [0, 0.02, 0.05, 0.1, 0.2, 0.3]\n",
    "scope_list = [\"model_non_robust\", \"model_non_robust\", \"model_robust\", \"hybrid\", \"model_non_robust\"]\n",
    "legend_list = ['non_robust', 'all layers trace reg', 'robust', 'hybrid', 'first layer trace reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot_acc_vs_eps(model_list, sess_list, eps_list, legend_list, scope_list, pgd = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black box accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_non_robust, model_all_reg, model_rob, model_hybrid, reg_model]\n",
    "sess_list = [sess_non_robust, sess_all_reg, sess_rob, sess_hybrid, sess_reg]\n",
    "eps_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "angle_list = [10, 15, 20, 25, 30, 35, 40]\n",
    "scope_list = [\"model_non_robust\", \"model_non_robust\", \"model_robust\", \"hybrid\", \"model_non_robust\"]\n",
    "legend_list = ['non_robust', 'all layers trace reg', 'robust', 'hybrid', 'first layer trace reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot_acc_vs_eps_black_box(model_list, sess_list, eps_list, angle_list, legend_list, scope_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_factor_non = sing_vals[0][0]\n",
    "sing_non = sing_vals[0]/norm_factor_non\n",
    "norm_factor_rob = sing_vals_robust[0][0]\n",
    "sing_rob = sing_vals_robust[0]/norm_factor_rob\n",
    "\n",
    "plt.loglog(range(len(sing_vals[0])), sing_non , label = \"non robust\")\n",
    "plt.loglog(range(len(sing_vals_robust[0])), sing_rob , label = \"robust\")\n",
    "plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(range(len(sing_vals[0])), sing_non , label = \"non robust\")\n",
    "plt.semilogy(range(len(sing_vals_robust[0])), sing_rob , label = \"robust\")\n",
    "plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(sing_vals[0])), sing_non , label = \"non robust\")\n",
    "plt.plot(range(len(sing_vals_robust[0])), sing_rob , label = \"robust\")\n",
    "plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_plots_layer_k(k):\n",
    "    norm_factor_non = sing_vals[k][0]\n",
    "    print(\"-----NORM FACTOR NON---\")\n",
    "    print(norm_factor_non)\n",
    "    sing_non = sing_vals[k]/norm_factor_non\n",
    "    norm_factor_rob = sing_vals_robust[k][0]\n",
    "    print(\"-----NORM FACTOR ROB---\")\n",
    "    print(norm_factor_rob)\n",
    "    sing_rob = sing_vals_robust[k]/norm_factor_rob\n",
    "    plt.loglog(range(len(sing_vals[k])), sing_non , label = \"non robust\")\n",
    "    plt.loglog(range(len(sing_vals_robust[k])), sing_rob , label = \"robust\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.show()\n",
    "    plt.semilogy(range(len(sing_vals[k])), sing_non , label = \"non robust\")\n",
    "    plt.semilogy(range(len(sing_vals_robust[k])), sing_rob , label = \"robust\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(sing_vals[k])), sing_non , label = \"non robust\")\n",
    "    plt.plot(range(len(sing_vals_robust[k])), sing_rob , label = \"robust\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(sing_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(8):\n",
    "    print(k)\n",
    "    print(\"-----------\")\n",
    "    all_plots_layer_k(k)\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(8):\n",
    "    print(k)\n",
    "    print(\"-----------\")\n",
    "    all_plots_layer_k(k)\n",
    "    print(\"-----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
