{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 14:26:49.828369 4638332352 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import os, random, time, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import ipdb\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../../')\n",
    "import feedforward_robust as ffr\n",
    "\n",
    "sys.path.append('../../../utils/')\n",
    "from utils.mnist_corruption import *\n",
    "from utils.utils_models import *\n",
    "from utils.utils_analysis import *\n",
    "from utils.utils_feedforward import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Read the counter\n",
    "ctr_file = \"../../counter.txt\"\n",
    "f = open(ctr_file, 'r')\n",
    "counter = f.readline()\n",
    "f.close()\n",
    "\n",
    "counter = 1 + int(counter)\n",
    "f = open(ctr_file,'w')\n",
    "f.write('{}'.format(counter))\n",
    "f.close()\n",
    "logfile = \"../../logs/results_\" + str(counter) + \".log\"\n",
    "\n",
    "logger = logging.getLogger(\"robustness\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Fashion MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot the labels\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)                                                                                         \n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_master, y_train_master = x_train[:30000], y_train[:30000]\n",
    "x_train_slave, y_train_slave = x_train[30000:], y_train[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten everything\n",
    "x_train_master_flat, input_shape = flatten_mnist(x_train_master) \n",
    "x_train_slave_flat, _ = flatten_mnist(x_train_slave)\n",
    "x_test_flat, _  = flatten_mnist(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "eps_train = 0.1                                                                                                                            \n",
    "eps_test = 0.1                                                                                                                             \n",
    "tensorboard_dir = \"../tb/\"                                                                                                                \n",
    "weights_dir = \"../weights/\"                                                                                                               \n",
    "load_weights = False                                                                                                              \n",
    "load_counter = 234                                                                                                            \n",
    "sigma = tf.nn.relu                                                                                                                         \n",
    "epochs, reg, lr = 10, 0.00, 1e-3    \n",
    "#epochs, reg, lr = 30, 0.00, 15e-4                                                                                                          \n",
    "pgd_eta, pgd_num_iter = 1e-2, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:26:51.084584 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "W0611 14:26:51.088459 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:36: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Created placeholders for x and y\n",
      "I0611 14:26:51.158060 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "W0611 14:26:51.160453 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0611 14:26:51.161144 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0611 14:26:51.161928 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:36: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0611 14:26:51.192192 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:40: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "Created layers and tensor for logits\n",
      "I0611 14:26:51.251615 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:26:51.260507 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "W0611 14:26:51.261676 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:49: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0611 14:26:51.263918 4638332352 deprecation.py:323] From ../../../feedforward_robust.py:53: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Added cross-entropy loss computation to the graph\n",
      "I0611 14:26:51.356524 4638332352 feedforward_robust.py:56] Added cross-entropy loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:26:51.357655 4638332352 feedforward_robust.py:62] Model graph was created\n",
      "W0611 14:26:51.359030 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:63: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0611 14:26:51.642474 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:78: The name tf.linalg.transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n",
      "\n",
      "W0611 14:26:51.684914 4638332352 deprecation.py:323] From ../../../feedforward_robust.py:739: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "W0611 14:26:51.685594 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:740: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 14:26:52.176807 4638332352 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n",
      "Epoch: 0001    cost: 0.609670069 \n",
      "I0611 14:26:53.927418 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 0.609670069 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:26:53.928781 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0002    cost: 0.431486010 \n",
      "I0611 14:26:54.968862 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 0.431486010 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:26:54.970636 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0003    cost: 0.387134931 \n",
      "I0611 14:26:55.880625 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 0.387134931 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:26:55.882165 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0004    cost: 0.356064284 \n",
      "I0611 14:26:56.703310 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 0.356064284 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:56.704815 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0005    cost: 0.334812181 \n",
      "I0611 14:26:57.680114 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 0.334812181 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:57.681258 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0006    cost: 0.317157990 \n",
      "I0611 14:26:58.590421 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 0.317157990 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:58.591544 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0007    cost: 0.302849520 \n",
      "I0611 14:26:59.656261 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 0.302849520 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:59.657632 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0008    cost: 0.290889399 \n",
      "I0611 14:27:00.566889 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 0.290889399 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:27:00.568195 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0009    cost: 0.274874339 \n",
      "I0611 14:27:01.483942 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 0.274874339 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 14:27:01.485228 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0010    cost: 0.265902430 \n",
      "I0611 14:27:02.501296 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 0.265902430 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 14:27:02.502623 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Optimization Finished!\n",
      "I0611 14:27:02.509266 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.284167\n",
      "I0611 14:27:02.673269 4638332352 feedforward_robust.py:726] Final Train Loss 0.284167\n",
      "Final Train Accuracy 0.892067:\n",
      "I0611 14:27:02.676182 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.892067:\n",
      "Model was trained on benign data\n",
      "I0611 14:27:02.679036 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:02.728605 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n",
      "I0611 14:27:02.889358 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:27:02.913572 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test accuracy and loss ----\n",
      "(0.43773252, 0.8555)\n",
      "----FGSM test accuracy and loss ----\n",
      "(10.643937, 0.0191)\n",
      "iteration: 0\n",
      "loss 0.935864\n",
      "iteration: 1\n",
      "loss 1.744425\n",
      "iteration: 2\n",
      "loss 2.847749\n",
      "iteration: 3\n",
      "loss 4.127424\n",
      "iteration: 4\n",
      "loss 5.486648\n",
      "iteration: 5\n",
      "loss 6.862092\n",
      "iteration: 6\n",
      "loss 8.207815\n",
      "iteration: 7\n",
      "loss 9.502996\n",
      "iteration: 8\n",
      "loss 10.736659\n",
      "iteration: 9\n",
      "loss 11.898533\n",
      "iteration: 10\n",
      "loss 12.987427\n",
      "iteration: 11\n",
      "loss 13.996099\n",
      "iteration: 12\n",
      "loss 14.924459\n",
      "iteration: 13\n",
      "loss 15.769581\n",
      "iteration: 14\n",
      "loss 16.531885\n",
      "iteration: 15\n",
      "loss 17.210794\n",
      "iteration: 16\n",
      "loss 17.804131\n",
      "iteration: 17\n",
      "loss 18.308901\n",
      "iteration: 18\n",
      "loss 18.724115\n",
      "iteration: 19\n",
      "loss 19.043907\n",
      "iteration: 20\n",
      "loss 19.303015\n",
      "iteration: 21\n",
      "loss 19.532196\n",
      "iteration: 22\n",
      "loss 19.734056\n",
      "iteration: 23\n",
      "loss 19.912531\n",
      "iteration: 24\n",
      "loss 20.069902\n",
      "iteration: 25\n",
      "loss 20.208094\n",
      "iteration: 26\n",
      "loss 20.329443\n",
      "iteration: 27\n",
      "loss 20.438034\n",
      "iteration: 28\n",
      "loss 20.533718\n",
      "iteration: 29\n",
      "loss 20.621565\n",
      "iteration: 30\n",
      "loss 20.698431\n",
      "iteration: 31\n",
      "loss 20.769518\n",
      "iteration: 32\n",
      "loss 20.832874\n",
      "iteration: 33\n",
      "loss 20.890278\n",
      "iteration: 34\n",
      "loss 20.944202\n",
      "iteration: 35\n",
      "loss 20.992964\n",
      "iteration: 36\n",
      "loss 21.038441\n",
      "iteration: 37\n",
      "loss 21.080757\n",
      "iteration: 38\n",
      "loss 21.120237\n",
      "iteration: 39\n",
      "loss 21.157461\n",
      "iteration: 40\n",
      "loss 21.191151\n",
      "iteration: 41\n",
      "loss 21.222754\n",
      "iteration: 42\n",
      "loss 21.251982\n",
      "iteration: 43\n",
      "loss 21.278606\n",
      "iteration: 44\n",
      "loss 21.304472\n",
      "iteration: 45\n",
      "loss 21.329252\n",
      "iteration: 46\n",
      "loss 21.352184\n",
      "iteration: 47\n",
      "loss 21.372662\n",
      "iteration: 48\n",
      "loss 21.393518\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:27:08.552792 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:27:08.555231 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:27:08.638644 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 21.411879\n",
      "----PGD test accuracy and loss ----\n",
      "(21.411879, 0.0034)\n"
     ]
    }
   ],
   "source": [
    "#Setup - Dataset stuff\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "hidden_sizes = [64, 64, 32]\n",
    "dataset = ((x_train_master_flat, y_train_master), (x_test_flat, y_test))\n",
    "\n",
    "scope_name = \"teacher_student_fashion\"\n",
    "if not load_weights:\n",
    "    with tf.variable_scope(scope_name, reuse = False) as scope:\n",
    "\n",
    "        logdir = tensorboard_dir + str(counter)\n",
    "\n",
    "        #Create model\n",
    "        writer = tf.summary.FileWriter(logdir)\n",
    "        model = ffr.RobustMLP(input_shape, hidden_sizes, num_classes, writer = writer, scope = scope_name, logger = logger, sigma = sigma)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"Created model successfully. Now going to train\")\n",
    "    \n",
    "        #Train model\n",
    "        model.fit(sess, x_train_master_flat, y_train_master, training_epochs = epochs, reg_op = reg , lr = lr)\n",
    "        \n",
    "        \"\"\"\n",
    "        #Save weights\n",
    "        weights = tf.trainable_variables()\n",
    "        #weights = model.get_weights()[0] + model.get_weights()[1]\n",
    "        saver = tf.train.Saver(weights)\n",
    "        weights_path = saver.save(sess, weights_dir + \"model_\" + str(counter) + \".ckpt\")\n",
    "        print(\"Saved model at %s\"%weights_path)\n",
    "        \"\"\"\n",
    "        \n",
    "        #Test model - regular, fgsm adv, pgd adv\n",
    "        loss_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "        print(\"----Regular test accuracy and loss ----\")\n",
    "        print((loss_reg, acc_reg))\n",
    "        \n",
    "        loss_fgsm, acc_fgsm = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = False)\n",
    "        print(\"----FGSM test accuracy and loss ----\")\n",
    "        print((loss_fgsm, acc_fgsm))\n",
    "        \n",
    "        loss_pgd, acc_pgd = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = True, eta=pgd_eta, num_iter = pgd_num_iter)\n",
    "        print(\"----PGD test accuracy and loss ----\")\n",
    "        print((loss_pgd , acc_pgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for slave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model was evaluated on benign data\n",
      "I0611 14:27:08.738597 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test accuracy and loss ----\n",
      "(0.43773252, 0.8555)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(scope_name, reuse = False) as scope:\n",
    "        loss_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "        print(\"----Regular test accuracy and loss ----\")\n",
    "        print((loss_reg, acc_reg))\n",
    "        \n",
    "        z_train_slave = model.get_prediction(sess, x_train_slave_flat)\n",
    "        z_test_slave = model.get_prediction(sess, x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.8703334,   1.7063155,  -5.6173   ,   8.1517725,  -2.121487 ,\n",
       "       -17.162003 ,  -1.7963917, -16.790625 , -10.707439 , -11.832216 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_slave[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train slave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup - Dataset stuff\n",
    "def slave_training():\n",
    "    epochs = 30\n",
    "    lr = 15e-4\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    hidden_sizes = [64, 64, 32]\n",
    "    dataset = ((x_train_slave_flat, z_train_slave), (x_test_flat, y_test))\n",
    "\n",
    "    scope_name = \"teacher_student_fashion\"\n",
    "    if not load_weights:\n",
    "        with tf.variable_scope(scope_name, reuse = tf.AUTO_REUSE) as scope:\n",
    "\n",
    "            logdir = tensorboard_dir + str(counter)\n",
    "\n",
    "            #Create model\n",
    "            writer = tf.summary.FileWriter(logdir)\n",
    "            model = ffr.RobustMLP(input_shape, hidden_sizes, num_classes, writer = writer, scope = scope_name, logger = logger, sigma = sigma, classification = False)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"Created model successfully. Now going to train\")\n",
    "\n",
    "            #Train model\n",
    "            model.fit(sess, x_train_slave_flat, z_train_slave, training_epochs = epochs, reg_op = reg , lr = lr)\n",
    "\n",
    "            \"\"\"\n",
    "            #Save weights\n",
    "            weights = tf.trainable_variables()\n",
    "            #weights = model.get_weights()[0] + model.get_weights()[1]\n",
    "            saver = tf.train.Saver(weights)\n",
    "            weights_path = saver.save(sess, weights_dir + \"model_\" + str(counter) + \".ckpt\")\n",
    "            print(\"Saved model at %s\"%weights_path)\n",
    "            \"\"\"\n",
    "            loss_real_train, acc_train = model.evaluate(sess, x_train_slave_flat, z_train_slave)\n",
    "\n",
    "            #Test model - regular, fgsm adv, pgd adv\n",
    "            loss_real_reg, acc_real_reg = model.evaluate(sess, x_test_flat, z_test_slave)\n",
    "            print(\"----Regular test loss and accuracy ----\")\n",
    "            print((loss_real_reg, acc_real_reg))\n",
    "            \n",
    "            loss_class_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "            print(\"----Real test loss and accuracy comparing to teacher ----\")\n",
    "            print((loss_class_reg, acc_reg))\n",
    "\n",
    "            loss_fgsm, acc_fgsm = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = False)\n",
    "            print(\"----FGSM test loss and accuracy ----\")\n",
    "            print((loss_fgsm, acc_fgsm))\n",
    "\n",
    "            loss_pgd, acc_pgd = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = True, eta=pgd_eta, num_iter = pgd_num_iter)\n",
    "            print(\"----PGD test loss and accuracy ----\")\n",
    "            print((loss_pgd , acc_pgd))\n",
    "            \n",
    "            slave_train_confidences = model.get_prediction(sess, x_train_slave_flat)\n",
    "            slave_test_confidences = model.get_prediction(sess, x_test_flat)\n",
    "            \n",
    "            return loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg, slave_train_confidences, slave_test_confidences\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:27:09.035940 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:27:09.042394 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0611 14:27:09.097213 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:27:09.103513 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:27:09.111549 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:27:09.112960 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.464981090 \n",
      "I0611 14:27:10.969558 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.464981090 \n",
      "Accuracy on batch: 0.781250\n",
      "I0611 14:27:10.970894 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.781250\n",
      "Epoch: 0002    cost: 3.922722844 \n",
      "I0611 14:27:12.047380 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.922722844 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:27:12.048506 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.763048109 \n",
      "I0611 14:27:13.097476 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.763048109 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:13.098880 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.253979416 \n",
      "I0611 14:27:14.054760 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.253979416 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:14.055893 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0005    cost: 1.977668763 \n",
      "I0611 14:27:15.036393 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.977668763 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:15.037527 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0006    cost: 1.782017305 \n",
      "I0611 14:27:15.962181 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.782017305 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:15.963409 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0007    cost: 1.642817586 \n",
      "I0611 14:27:16.931200 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 1.642817586 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:16.932431 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0008    cost: 1.530502498 \n",
      "I0611 14:27:17.878751 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 1.530502498 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:17.880223 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0009    cost: 1.438830145 \n",
      "I0611 14:27:18.900653 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 1.438830145 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:18.901835 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0010    cost: 1.367732002 \n",
      "I0611 14:27:20.004456 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 1.367732002 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:20.005676 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0011    cost: 1.307706801 \n",
      "I0611 14:27:20.996826 4638332352 feedforward_robust.py:716] Epoch: 0011    cost: 1.307706801 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:20.998177 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0012    cost: 1.263038780 \n",
      "I0611 14:27:22.028741 4638332352 feedforward_robust.py:716] Epoch: 0012    cost: 1.263038780 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:22.030000 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0013    cost: 1.221085133 \n",
      "I0611 14:27:23.007533 4638332352 feedforward_robust.py:716] Epoch: 0013    cost: 1.221085133 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:23.008730 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0014    cost: 1.179518567 \n",
      "I0611 14:27:24.041198 4638332352 feedforward_robust.py:716] Epoch: 0014    cost: 1.179518567 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:24.042685 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0015    cost: 1.145948007 \n",
      "I0611 14:27:25.194231 4638332352 feedforward_robust.py:716] Epoch: 0015    cost: 1.145948007 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:25.195761 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0016    cost: 1.112495736 \n",
      "I0611 14:27:26.239727 4638332352 feedforward_robust.py:716] Epoch: 0016    cost: 1.112495736 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:26.240697 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0017    cost: 1.087070491 \n",
      "I0611 14:27:27.284986 4638332352 feedforward_robust.py:716] Epoch: 0017    cost: 1.087070491 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:27.286237 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0018    cost: 1.062921593 \n",
      "I0611 14:27:28.319205 4638332352 feedforward_robust.py:716] Epoch: 0018    cost: 1.062921593 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:28.320307 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0019    cost: 1.038175433 \n",
      "I0611 14:27:29.344624 4638332352 feedforward_robust.py:716] Epoch: 0019    cost: 1.038175433 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:29.345767 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0020    cost: 1.014724208 \n",
      "I0611 14:27:30.299205 4638332352 feedforward_robust.py:716] Epoch: 0020    cost: 1.014724208 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:30.300441 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0021    cost: 0.998925812 \n",
      "I0611 14:27:31.350437 4638332352 feedforward_robust.py:716] Epoch: 0021    cost: 0.998925812 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:31.351994 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0022    cost: 0.980537726 \n",
      "I0611 14:27:32.350191 4638332352 feedforward_robust.py:716] Epoch: 0022    cost: 0.980537726 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:32.351145 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0023    cost: 0.958666797 \n",
      "I0611 14:27:33.281946 4638332352 feedforward_robust.py:716] Epoch: 0023    cost: 0.958666797 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:33.283088 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0024    cost: 0.944630408 \n",
      "I0611 14:27:34.309969 4638332352 feedforward_robust.py:716] Epoch: 0024    cost: 0.944630408 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:34.311142 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0025    cost: 0.931947221 \n",
      "I0611 14:27:35.291173 4638332352 feedforward_robust.py:716] Epoch: 0025    cost: 0.931947221 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:35.292663 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0026    cost: 0.924086434 \n",
      "I0611 14:27:36.271754 4638332352 feedforward_robust.py:716] Epoch: 0026    cost: 0.924086434 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:36.273233 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0027    cost: 0.912875397 \n",
      "I0611 14:27:37.214976 4638332352 feedforward_robust.py:716] Epoch: 0027    cost: 0.912875397 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:37.216269 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0028    cost: 0.904915964 \n",
      "I0611 14:27:38.173861 4638332352 feedforward_robust.py:716] Epoch: 0028    cost: 0.904915964 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:38.175364 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0029    cost: 0.899109767 \n",
      "I0611 14:27:39.122177 4638332352 feedforward_robust.py:716] Epoch: 0029    cost: 0.899109767 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:39.123642 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0030    cost: 0.882714187 \n",
      "I0611 14:27:40.038785 4638332352 feedforward_robust.py:716] Epoch: 0030    cost: 0.882714187 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:40.040468 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Optimization Finished!\n",
      "I0611 14:27:40.043919 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.932856\n",
      "I0611 14:27:40.186693 4638332352 feedforward_robust.py:726] Final Train Loss 0.932856\n",
      "Final Train Accuracy 0.954900:\n",
      "I0611 14:27:40.195276 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.954900:\n",
      "Model was trained on benign data\n",
      "I0611 14:27:40.197379 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:40.268064 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:40.311646 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:40.335101 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 14:27:40.502585 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test loss and accuracy ----\n",
      "(1.2695092, 0.9485)\n",
      "----Real test loss and accuracy comparing to teacher ----\n",
      "(208.2667, 0.8521)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:27:40.519871 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----FGSM test loss and accuracy ----\n",
      "(1325.2003, 0.7636)\n",
      "iteration: 0\n",
      "loss 1.043663\n",
      "iteration: 1\n",
      "loss 2.063286\n",
      "iteration: 2\n",
      "loss 3.448260\n",
      "iteration: 3\n",
      "loss 5.007183\n",
      "iteration: 4\n",
      "loss 6.605892\n",
      "iteration: 5\n",
      "loss 8.181146\n",
      "iteration: 6\n",
      "loss 9.702505\n",
      "iteration: 7\n",
      "loss 11.152001\n",
      "iteration: 8\n",
      "loss 12.524700\n",
      "iteration: 9\n",
      "loss 13.810907\n",
      "iteration: 10\n",
      "loss 15.011579\n",
      "iteration: 11\n",
      "loss 16.122969\n",
      "iteration: 12\n",
      "loss 17.142822\n",
      "iteration: 13\n",
      "loss 18.069492\n",
      "iteration: 14\n",
      "loss 18.902082\n",
      "iteration: 15\n",
      "loss 19.641357\n",
      "iteration: 16\n",
      "loss 20.283484\n",
      "iteration: 17\n",
      "loss 20.827827\n",
      "iteration: 18\n",
      "loss 21.273535\n",
      "iteration: 19\n",
      "loss 21.621094\n",
      "iteration: 20\n",
      "loss 21.898458\n",
      "iteration: 21\n",
      "loss 22.143703\n",
      "iteration: 22\n",
      "loss 22.358238\n",
      "iteration: 23\n",
      "loss 22.544432\n",
      "iteration: 24\n",
      "loss 22.707237\n",
      "iteration: 25\n",
      "loss 22.848782\n",
      "iteration: 26\n",
      "loss 22.971888\n",
      "iteration: 27\n",
      "loss 23.080063\n",
      "iteration: 28\n",
      "loss 23.175508\n",
      "iteration: 29\n",
      "loss 23.258404\n",
      "iteration: 30\n",
      "loss 23.335562\n",
      "iteration: 31\n",
      "loss 23.403860\n",
      "iteration: 32\n",
      "loss 23.464531\n",
      "iteration: 33\n",
      "loss 23.522488\n",
      "iteration: 34\n",
      "loss 23.572340\n",
      "iteration: 35\n",
      "loss 23.621155\n",
      "iteration: 36\n",
      "loss 23.663237\n",
      "iteration: 37\n",
      "loss 23.701941\n",
      "iteration: 38\n",
      "loss 23.739609\n",
      "iteration: 39\n",
      "loss 23.773598\n",
      "iteration: 40\n",
      "loss 23.806517\n",
      "iteration: 41\n",
      "loss 23.834312\n",
      "iteration: 42\n",
      "loss 23.862207\n",
      "iteration: 43\n",
      "loss 23.887941\n",
      "iteration: 44\n",
      "loss 23.911215\n",
      "iteration: 45\n",
      "loss 23.932909\n",
      "iteration: 46\n",
      "loss 23.954529\n",
      "iteration: 47\n",
      "loss 23.975475\n",
      "iteration: 48\n",
      "loss 23.992384\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:27:45.461327 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:27:45.462692 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:27:45.506175 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 24.011793\n",
      "----PGD test loss and accuracy ----\n",
      "(683.9786, 0.0009)\n"
     ]
    }
   ],
   "source": [
    "tup = slave_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.93285626,\n",
       " 0.9549,\n",
       " 1.2695092,\n",
       " 0.9485,\n",
       " 0.8521,\n",
       " array([[ -2.4738553 ,   1.4548903 ,  -5.2864723 , ..., -16.553606  ,\n",
       "          -9.862367  , -11.722542  ],\n",
       "        [ -2.777988  ,  -0.2097955 ,  -6.139147  , ..., -11.253925  ,\n",
       "          -4.0789533 , -11.227329  ],\n",
       "        [ -7.0907645 ,  -6.7067056 ,  -8.018333  , ...,   8.033091  ,\n",
       "          -5.7001867 ,  -2.5510015 ],\n",
       "        ...,\n",
       "        [ -3.5365465 ,  -2.6542697 ,  -4.6018915 , ..., -13.083588  ,\n",
       "          -9.382924  ,  -9.573526  ],\n",
       "        [  3.6126416 ,  -5.420528  ,  -0.13431433, ..., -12.910023  ,\n",
       "          -5.582261  ,  -7.7274966 ],\n",
       "        [ -6.3852077 ,  -7.5782604 ,  -8.277701  , ...,  -3.2700589 ,\n",
       "          -9.510182  ,  -8.48611   ]], dtype=float32),\n",
       " array([[ -7.1515765 ,  -5.5476246 ,  -7.131644  , ...,   1.7403907 ,\n",
       "          -8.918869  ,   5.581065  ],\n",
       "        [ -7.2639294 , -14.082399  ,   6.8233366 , ..., -17.89693   ,\n",
       "         -11.568522  , -12.727906  ],\n",
       "        [ -5.3687563 ,  16.649733  , -16.944101  , ...,  -7.1560364 ,\n",
       "         -12.090617  , -13.448195  ],\n",
       "        ...,\n",
       "        [ -0.44599098,  -9.255183  ,  -1.6544535 , ...,  -6.32419   ,\n",
       "           8.118214  ,  -8.542353  ],\n",
       "        [ -7.0366855 ,  12.588056  , -10.776271  , ...,  -2.8055482 ,\n",
       "         -10.18191   ,  -5.438324  ],\n",
       "        [ -4.6907697 ,  -6.569682  ,  -6.450926  , ...,  -1.2722718 ,\n",
       "          -4.40865   ,  -8.228916  ]], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['mse on z_train'] = []\n",
    "df['acc on z_train'] = []\n",
    "df['mse on z_test'] = []\n",
    "df['acc on z_test'] = []\n",
    "df['acc on y_test'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:27:45.891708 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:27:45.900774 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0611 14:27:45.982398 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:27:45.989894 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:27:46.009101 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:27:46.012348 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.209017649 \n",
      "I0611 14:27:47.615728 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.209017649 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:27:47.616786 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0002    cost: 3.917461560 \n",
      "I0611 14:27:48.520066 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.917461560 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:27:48.521093 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.749678619 \n",
      "I0611 14:27:49.405025 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.749678619 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:49.406166 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.248680972 \n",
      "I0611 14:27:50.298635 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.248680972 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:50.299989 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0005    cost: 1.952400131 \n",
      "I0611 14:27:51.217540 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.952400131 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:51.218691 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0006    cost: 1.744025418 \n",
      "I0611 14:27:52.079259 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.744025418 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:52.080696 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0007    cost: 1.596262608 \n",
      "I0611 14:27:53.028803 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 1.596262608 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:53.031250 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0008    cost: 1.480016434 \n",
      "I0611 14:27:54.019062 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 1.480016434 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:54.021106 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0009    cost: 1.397437789 \n",
      "I0611 14:27:55.187309 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 1.397437789 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:55.188533 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0010    cost: 1.310127477 \n",
      "I0611 14:27:56.222513 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 1.310127477 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:56.223793 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0011    cost: 1.244151702 \n",
      "I0611 14:27:57.338630 4638332352 feedforward_robust.py:716] Epoch: 0011    cost: 1.244151702 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:57.339766 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0012    cost: 1.192086148 \n",
      "I0611 14:27:58.344254 4638332352 feedforward_robust.py:716] Epoch: 0012    cost: 1.192086148 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:58.346115 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0013    cost: 1.140497389 \n",
      "I0611 14:27:59.327431 4638332352 feedforward_robust.py:716] Epoch: 0013    cost: 1.140497389 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:59.328470 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0014    cost: 1.094745758 \n",
      "I0611 14:28:00.213254 4638332352 feedforward_robust.py:716] Epoch: 0014    cost: 1.094745758 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:28:00.214677 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0015    cost: 1.062556699 \n",
      "I0611 14:28:01.091934 4638332352 feedforward_robust.py:716] Epoch: 0015    cost: 1.062556699 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:28:01.093526 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0016    cost: 1.032426415 \n",
      "I0611 14:28:02.031932 4638332352 feedforward_robust.py:716] Epoch: 0016    cost: 1.032426415 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:28:02.033285 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0017    cost: 1.002116164 \n",
      "I0611 14:28:03.035923 4638332352 feedforward_robust.py:716] Epoch: 0017    cost: 1.002116164 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:03.037374 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0018    cost: 0.977076611 \n",
      "I0611 14:28:03.968644 4638332352 feedforward_robust.py:716] Epoch: 0018    cost: 0.977076611 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:03.970159 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0019    cost: 0.958430828 \n",
      "I0611 14:28:04.850378 4638332352 feedforward_robust.py:716] Epoch: 0019    cost: 0.958430828 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:04.851855 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0020    cost: 0.938197514 \n",
      "I0611 14:28:05.816059 4638332352 feedforward_robust.py:716] Epoch: 0020    cost: 0.938197514 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:05.817106 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0021    cost: 0.927383138 \n",
      "I0611 14:28:06.800130 4638332352 feedforward_robust.py:716] Epoch: 0021    cost: 0.927383138 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:06.801165 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0022    cost: 0.907024331 \n",
      "I0611 14:28:07.779160 4638332352 feedforward_robust.py:716] Epoch: 0022    cost: 0.907024331 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:07.780378 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0023    cost: 0.894129634 \n",
      "I0611 14:28:08.673870 4638332352 feedforward_robust.py:716] Epoch: 0023    cost: 0.894129634 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:08.675154 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0024    cost: 0.882782814 \n",
      "I0611 14:28:09.651628 4638332352 feedforward_robust.py:716] Epoch: 0024    cost: 0.882782814 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:09.652976 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0025    cost: 0.865818638 \n",
      "I0611 14:28:10.611038 4638332352 feedforward_robust.py:716] Epoch: 0025    cost: 0.865818638 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:10.612429 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0026    cost: 0.852832034 \n",
      "I0611 14:28:11.524030 4638332352 feedforward_robust.py:716] Epoch: 0026    cost: 0.852832034 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:11.526011 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0027    cost: 0.843932601 \n",
      "I0611 14:28:12.522008 4638332352 feedforward_robust.py:716] Epoch: 0027    cost: 0.843932601 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:12.523252 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0028    cost: 0.828729980 \n",
      "I0611 14:28:13.464040 4638332352 feedforward_robust.py:716] Epoch: 0028    cost: 0.828729980 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:13.465201 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0029    cost: 0.818764694 \n",
      "I0611 14:28:14.391415 4638332352 feedforward_robust.py:716] Epoch: 0029    cost: 0.818764694 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:14.392730 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0030    cost: 0.804197596 \n",
      "I0611 14:28:15.298981 4638332352 feedforward_robust.py:716] Epoch: 0030    cost: 0.804197596 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:15.300415 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Optimization Finished!\n",
      "I0611 14:28:15.301775 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.857293\n",
      "I0611 14:28:15.425322 4638332352 feedforward_robust.py:726] Final Train Loss 0.857293\n",
      "Final Train Accuracy 0.959167:\n",
      "I0611 14:28:15.426632 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.959167:\n",
      "Model was trained on benign data\n",
      "I0611 14:28:15.428823 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:15.496634 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:15.536639 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:15.561050 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 14:28:15.698168 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:28:15.714685 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test loss and accuracy ----\n",
      "(1.1885988, 0.9496)\n",
      "----Real test loss and accuracy comparing to teacher ----\n",
      "(208.79608, 0.8478)\n",
      "----FGSM test loss and accuracy ----\n",
      "(1362.2505, 0.742)\n",
      "iteration: 0\n",
      "loss 1.083219\n",
      "iteration: 1\n",
      "loss 2.167089\n",
      "iteration: 2\n",
      "loss 3.603489\n",
      "iteration: 3\n",
      "loss 5.179325\n",
      "iteration: 4\n",
      "loss 6.805217\n",
      "iteration: 5\n",
      "loss 8.416625\n",
      "iteration: 6\n",
      "loss 9.972460\n",
      "iteration: 7\n",
      "loss 11.456193\n",
      "iteration: 8\n",
      "loss 12.856785\n",
      "iteration: 9\n",
      "loss 14.171765\n",
      "iteration: 10\n",
      "loss 15.400415\n",
      "iteration: 11\n",
      "loss 16.543215\n",
      "iteration: 12\n",
      "loss 17.595863\n",
      "iteration: 13\n",
      "loss 18.557697\n",
      "iteration: 14\n",
      "loss 19.426062\n",
      "iteration: 15\n",
      "loss 20.197735\n",
      "iteration: 16\n",
      "loss 20.871138\n",
      "iteration: 17\n",
      "loss 21.444880\n",
      "iteration: 18\n",
      "loss 21.914690\n",
      "iteration: 19\n",
      "loss 22.279713\n",
      "iteration: 20\n",
      "loss 22.573040\n",
      "iteration: 21\n",
      "loss 22.831558\n",
      "iteration: 22\n",
      "loss 23.057901\n",
      "iteration: 23\n",
      "loss 23.254999\n",
      "iteration: 24\n",
      "loss 23.428110\n",
      "iteration: 25\n",
      "loss 23.580078\n",
      "iteration: 26\n",
      "loss 23.714197\n",
      "iteration: 27\n",
      "loss 23.830038\n",
      "iteration: 28\n",
      "loss 23.937408\n",
      "iteration: 29\n",
      "loss 24.029531\n",
      "iteration: 30\n",
      "loss 24.113491\n",
      "iteration: 31\n",
      "loss 24.187418\n",
      "iteration: 32\n",
      "loss 24.256027\n",
      "iteration: 33\n",
      "loss 24.316198\n",
      "iteration: 34\n",
      "loss 24.372545\n",
      "iteration: 35\n",
      "loss 24.421835\n",
      "iteration: 36\n",
      "loss 24.468838\n",
      "iteration: 37\n",
      "loss 24.511127\n",
      "iteration: 38\n",
      "loss 24.552759\n",
      "iteration: 39\n",
      "loss 24.587969\n",
      "iteration: 40\n",
      "loss 24.623480\n",
      "iteration: 41\n",
      "loss 24.655540\n",
      "iteration: 42\n",
      "loss 24.686102\n",
      "iteration: 43\n",
      "loss 24.712696\n",
      "iteration: 44\n",
      "loss 24.741743\n",
      "iteration: 45\n",
      "loss 24.765009\n",
      "iteration: 46\n",
      "loss 24.787989\n",
      "iteration: 47\n",
      "loss 24.809597\n",
      "iteration: 48\n",
      "loss 24.830162\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:28:20.914702 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:28:20.916465 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:28:20.971352 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 24.849209\n",
      "----PGD test loss and accuracy ----\n",
      "(723.0785, 0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:28:21.212563 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:28:21.221371 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0611 14:28:21.276872 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:28:21.283307 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:28:21.294542 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:28:21.295874 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.464040700 \n",
      "I0611 14:28:23.039726 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.464040700 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:28:23.040753 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0002    cost: 3.701160542 \n",
      "I0611 14:28:24.017629 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.701160542 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:28:24.019115 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.655647429 \n",
      "I0611 14:28:24.903921 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.655647429 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:24.905468 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.176999009 \n",
      "I0611 14:28:25.798273 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.176999009 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:25.799550 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0005    cost: 1.892996802 \n",
      "I0611 14:28:26.698386 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.892996802 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:26.699866 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0006    cost: 1.689311388 \n",
      "I0611 14:28:27.630409 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.689311388 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:27.631635 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n"
     ]
    }
   ],
   "source": [
    "train_confidences = []\n",
    "test_confidences = []\n",
    "for i in range(3):\n",
    "    loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg, slave_train_confidences, slave_test_confidences = slave_training()\n",
    "    df.loc[i] = [loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg]\n",
    "    train_confidences.append(slave_train_confidences)\n",
    "    test_confidences.append(slave_test_confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"ts_fashion_results.xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
