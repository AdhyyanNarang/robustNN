{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 14:26:49.828369 4638332352 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import os, random, time, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import ipdb\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../../')\n",
    "import feedforward_robust as ffr\n",
    "\n",
    "sys.path.append('../../../utils/')\n",
    "from utils.mnist_corruption import *\n",
    "from utils.utils_models import *\n",
    "from utils.utils_analysis import *\n",
    "from utils.utils_feedforward import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Read the counter\n",
    "ctr_file = \"../../counter.txt\"\n",
    "f = open(ctr_file, 'r')\n",
    "counter = f.readline()\n",
    "f.close()\n",
    "\n",
    "counter = 1 + int(counter)\n",
    "f = open(ctr_file,'w')\n",
    "f.write('{}'.format(counter))\n",
    "f.close()\n",
    "logfile = \"../../logs/results_\" + str(counter) + \".log\"\n",
    "\n",
    "logger = logging.getLogger(\"robustness\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Fashion MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot the labels\n",
    "num_classes = 10\n",
    "y_train_oh = keras.utils.to_categorical(y_train, num_classes)                                                                                         \n",
    "y_test_oh = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 0.9\n",
    "y_train_oh = y_train_oh * max_val\n",
    "remainder = (1 - max_val)/9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = np.ones(y_train_oh.shape)\n",
    "for i in range(len(y_train_oh)):\n",
    "    correct_index = y_train[i]\n",
    "    to_add[i, correct_index] = 0\n",
    "to_add = to_add * remainder\n",
    "y_train_oh = y_train_oh + to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01111111, 0.01111111, 0.01111111, 0.01111111, 0.01111111,\n",
       "       0.01111111, 0.01111111, 0.01111111, 0.01111111, 0.        ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_master, y_train_master = x_train[:30000], y_train[:30000]\n",
    "x_train_slave, y_train_slave = x_train[30000:], y_train[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten everything\n",
    "x_train_master_flat, input_shape = flatten_mnist(x_train_master) \n",
    "x_train_slave_flat, _ = flatten_mnist(x_train_slave)\n",
    "x_test_flat, _  = flatten_mnist(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "eps_train = 0.1                                                                                                                            \n",
    "eps_test = 0.1                                                                                                                             \n",
    "tensorboard_dir = \"../tb/\"                                                                                                                \n",
    "weights_dir = \"../weights/\"                                                                                                               \n",
    "load_weights = False                                                                                                              \n",
    "load_counter = 234                                                                                                            \n",
    "sigma = tf.nn.relu                                                                                                                         \n",
    "epochs, reg, lr = 10, 0.00, 1e-3    \n",
    "#epochs, reg, lr = 30, 0.00, 15e-4                                                                                                          \n",
    "pgd_eta, pgd_num_iter = 1e-2, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:26:51.084584 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "W0611 14:26:51.088459 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:36: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Created placeholders for x and y\n",
      "I0611 14:26:51.158060 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "W0611 14:26:51.160453 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0611 14:26:51.161144 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0611 14:26:51.161928 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:36: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0611 14:26:51.192192 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:40: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "Created layers and tensor for logits\n",
      "I0611 14:26:51.251615 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:26:51.260507 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "W0611 14:26:51.261676 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:49: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0611 14:26:51.263918 4638332352 deprecation.py:323] From ../../../feedforward_robust.py:53: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Added cross-entropy loss computation to the graph\n",
      "I0611 14:26:51.356524 4638332352 feedforward_robust.py:56] Added cross-entropy loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:26:51.357655 4638332352 feedforward_robust.py:62] Model graph was created\n",
      "W0611 14:26:51.359030 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:63: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0611 14:26:51.642474 4638332352 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:78: The name tf.linalg.transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n",
      "\n",
      "W0611 14:26:51.684914 4638332352 deprecation.py:323] From ../../../feedforward_robust.py:739: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "W0611 14:26:51.685594 4638332352 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:740: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 14:26:52.176807 4638332352 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n",
      "Epoch: 0001    cost: 0.609670069 \n",
      "I0611 14:26:53.927418 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 0.609670069 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:26:53.928781 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0002    cost: 0.431486010 \n",
      "I0611 14:26:54.968862 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 0.431486010 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:26:54.970636 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0003    cost: 0.387134931 \n",
      "I0611 14:26:55.880625 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 0.387134931 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:26:55.882165 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0004    cost: 0.356064284 \n",
      "I0611 14:26:56.703310 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 0.356064284 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:56.704815 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0005    cost: 0.334812181 \n",
      "I0611 14:26:57.680114 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 0.334812181 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:57.681258 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0006    cost: 0.317157990 \n",
      "I0611 14:26:58.590421 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 0.317157990 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:58.591544 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0007    cost: 0.302849520 \n",
      "I0611 14:26:59.656261 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 0.302849520 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:26:59.657632 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0008    cost: 0.290889399 \n",
      "I0611 14:27:00.566889 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 0.290889399 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:27:00.568195 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0009    cost: 0.274874339 \n",
      "I0611 14:27:01.483942 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 0.274874339 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 14:27:01.485228 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0010    cost: 0.265902430 \n",
      "I0611 14:27:02.501296 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 0.265902430 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 14:27:02.502623 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Optimization Finished!\n",
      "I0611 14:27:02.509266 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.284167\n",
      "I0611 14:27:02.673269 4638332352 feedforward_robust.py:726] Final Train Loss 0.284167\n",
      "Final Train Accuracy 0.892067:\n",
      "I0611 14:27:02.676182 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.892067:\n",
      "Model was trained on benign data\n",
      "I0611 14:27:02.679036 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:02.728605 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n",
      "I0611 14:27:02.889358 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:27:02.913572 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test accuracy and loss ----\n",
      "(0.43773252, 0.8555)\n",
      "----FGSM test accuracy and loss ----\n",
      "(10.643937, 0.0191)\n",
      "iteration: 0\n",
      "loss 0.935864\n",
      "iteration: 1\n",
      "loss 1.744425\n",
      "iteration: 2\n",
      "loss 2.847749\n",
      "iteration: 3\n",
      "loss 4.127424\n",
      "iteration: 4\n",
      "loss 5.486648\n",
      "iteration: 5\n",
      "loss 6.862092\n",
      "iteration: 6\n",
      "loss 8.207815\n",
      "iteration: 7\n",
      "loss 9.502996\n",
      "iteration: 8\n",
      "loss 10.736659\n",
      "iteration: 9\n",
      "loss 11.898533\n",
      "iteration: 10\n",
      "loss 12.987427\n",
      "iteration: 11\n",
      "loss 13.996099\n",
      "iteration: 12\n",
      "loss 14.924459\n",
      "iteration: 13\n",
      "loss 15.769581\n",
      "iteration: 14\n",
      "loss 16.531885\n",
      "iteration: 15\n",
      "loss 17.210794\n",
      "iteration: 16\n",
      "loss 17.804131\n",
      "iteration: 17\n",
      "loss 18.308901\n",
      "iteration: 18\n",
      "loss 18.724115\n",
      "iteration: 19\n",
      "loss 19.043907\n",
      "iteration: 20\n",
      "loss 19.303015\n",
      "iteration: 21\n",
      "loss 19.532196\n",
      "iteration: 22\n",
      "loss 19.734056\n",
      "iteration: 23\n",
      "loss 19.912531\n",
      "iteration: 24\n",
      "loss 20.069902\n",
      "iteration: 25\n",
      "loss 20.208094\n",
      "iteration: 26\n",
      "loss 20.329443\n",
      "iteration: 27\n",
      "loss 20.438034\n",
      "iteration: 28\n",
      "loss 20.533718\n",
      "iteration: 29\n",
      "loss 20.621565\n",
      "iteration: 30\n",
      "loss 20.698431\n",
      "iteration: 31\n",
      "loss 20.769518\n",
      "iteration: 32\n",
      "loss 20.832874\n",
      "iteration: 33\n",
      "loss 20.890278\n",
      "iteration: 34\n",
      "loss 20.944202\n",
      "iteration: 35\n",
      "loss 20.992964\n",
      "iteration: 36\n",
      "loss 21.038441\n",
      "iteration: 37\n",
      "loss 21.080757\n",
      "iteration: 38\n",
      "loss 21.120237\n",
      "iteration: 39\n",
      "loss 21.157461\n",
      "iteration: 40\n",
      "loss 21.191151\n",
      "iteration: 41\n",
      "loss 21.222754\n",
      "iteration: 42\n",
      "loss 21.251982\n",
      "iteration: 43\n",
      "loss 21.278606\n",
      "iteration: 44\n",
      "loss 21.304472\n",
      "iteration: 45\n",
      "loss 21.329252\n",
      "iteration: 46\n",
      "loss 21.352184\n",
      "iteration: 47\n",
      "loss 21.372662\n",
      "iteration: 48\n",
      "loss 21.393518\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:27:08.552792 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:27:08.555231 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:27:08.638644 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 21.411879\n",
      "----PGD test accuracy and loss ----\n",
      "(21.411879, 0.0034)\n"
     ]
    }
   ],
   "source": [
    "#Setup - Dataset stuff\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "hidden_sizes = [64, 64, 32]\n",
    "dataset = ((x_train_master_flat, y_train_master), (x_test_flat, y_test))\n",
    "\n",
    "scope_name = \"teacher_student_fashion\"\n",
    "if not load_weights:\n",
    "    with tf.variable_scope(scope_name, reuse = False) as scope:\n",
    "\n",
    "        logdir = tensorboard_dir + str(counter)\n",
    "\n",
    "        #Create model\n",
    "        writer = tf.summary.FileWriter(logdir)\n",
    "        model = ffr.RobustMLP(input_shape, hidden_sizes, num_classes, writer = writer, scope = scope_name, logger = logger, sigma = sigma)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"Created model successfully. Now going to train\")\n",
    "    \n",
    "        #Train model\n",
    "        model.fit(sess, x_train_master_flat, y_train_master, training_epochs = epochs, reg_op = reg , lr = lr)\n",
    "        \n",
    "        \"\"\"\n",
    "        #Save weights\n",
    "        weights = tf.trainable_variables()\n",
    "        #weights = model.get_weights()[0] + model.get_weights()[1]\n",
    "        saver = tf.train.Saver(weights)\n",
    "        weights_path = saver.save(sess, weights_dir + \"model_\" + str(counter) + \".ckpt\")\n",
    "        print(\"Saved model at %s\"%weights_path)\n",
    "        \"\"\"\n",
    "        \n",
    "        #Test model - regular, fgsm adv, pgd adv\n",
    "        loss_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "        print(\"----Regular test accuracy and loss ----\")\n",
    "        print((loss_reg, acc_reg))\n",
    "        \n",
    "        loss_fgsm, acc_fgsm = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = False)\n",
    "        print(\"----FGSM test accuracy and loss ----\")\n",
    "        print((loss_fgsm, acc_fgsm))\n",
    "        \n",
    "        loss_pgd, acc_pgd = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = True, eta=pgd_eta, num_iter = pgd_num_iter)\n",
    "        print(\"----PGD test accuracy and loss ----\")\n",
    "        print((loss_pgd , acc_pgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for slave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model was evaluated on benign data\n",
      "I0611 14:27:08.738597 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test accuracy and loss ----\n",
      "(0.43773252, 0.8555)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(scope_name, reuse = False) as scope:\n",
    "        loss_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "        print(\"----Regular test accuracy and loss ----\")\n",
    "        print((loss_reg, acc_reg))\n",
    "        \n",
    "        z_train_slave = model.get_prediction(sess, x_train_slave_flat)\n",
    "        z_test_slave = model.get_prediction(sess, x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.8703334,   1.7063155,  -5.6173   ,   8.1517725,  -2.121487 ,\n",
       "       -17.162003 ,  -1.7963917, -16.790625 , -10.707439 , -11.832216 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_slave[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train slave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup - Dataset stuff\n",
    "def slave_training():\n",
    "    epochs = 30\n",
    "    lr = 15e-4\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    hidden_sizes = [64, 64, 32]\n",
    "    dataset = ((x_train_slave_flat, z_train_slave), (x_test_flat, y_test))\n",
    "\n",
    "    scope_name = \"teacher_student_fashion\"\n",
    "    if not load_weights:\n",
    "        with tf.variable_scope(scope_name, reuse = tf.AUTO_REUSE) as scope:\n",
    "\n",
    "            logdir = tensorboard_dir + str(counter)\n",
    "\n",
    "            #Create model\n",
    "            writer = tf.summary.FileWriter(logdir)\n",
    "            model = ffr.RobustMLP(input_shape, hidden_sizes, num_classes, writer = writer, scope = scope_name, logger = logger, sigma = sigma, classification = False)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"Created model successfully. Now going to train\")\n",
    "\n",
    "            #Train model\n",
    "            model.fit(sess, x_train_slave_flat, z_train_slave, training_epochs = epochs, reg_op = reg , lr = lr)\n",
    "\n",
    "            \"\"\"\n",
    "            #Save weights\n",
    "            weights = tf.trainable_variables()\n",
    "            #weights = model.get_weights()[0] + model.get_weights()[1]\n",
    "            saver = tf.train.Saver(weights)\n",
    "            weights_path = saver.save(sess, weights_dir + \"model_\" + str(counter) + \".ckpt\")\n",
    "            print(\"Saved model at %s\"%weights_path)\n",
    "            \"\"\"\n",
    "            loss_real_train, acc_train = model.evaluate(sess, x_train_slave_flat, z_train_slave)\n",
    "\n",
    "            #Test model - regular, fgsm adv, pgd adv\n",
    "            loss_real_reg, acc_real_reg = model.evaluate(sess, x_test_flat, z_test_slave)\n",
    "            print(\"----Regular test loss and accuracy ----\")\n",
    "            print((loss_real_reg, acc_real_reg))\n",
    "            \n",
    "            loss_class_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "            print(\"----Real test loss and accuracy comparing to teacher ----\")\n",
    "            print((loss_class_reg, acc_reg))\n",
    "\n",
    "            loss_fgsm, acc_fgsm = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = False)\n",
    "            print(\"----FGSM test loss and accuracy ----\")\n",
    "            print((loss_fgsm, acc_fgsm))\n",
    "\n",
    "            loss_pgd, acc_pgd = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = True, eta=pgd_eta, num_iter = pgd_num_iter)\n",
    "            print(\"----PGD test loss and accuracy ----\")\n",
    "            print((loss_pgd , acc_pgd))\n",
    "            \n",
    "            slave_train_confidences = model.get_prediction(sess, x_train_slave_flat)\n",
    "            slave_test_confidences = model.get_prediction(sess, x_test_flat)\n",
    "            \n",
    "            return loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg, slave_train_confidences, slave_test_confidences\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:27:09.035940 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:27:09.042394 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0611 14:27:09.097213 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:27:09.103513 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:27:09.111549 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:27:09.112960 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.464981090 \n",
      "I0611 14:27:10.969558 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.464981090 \n",
      "Accuracy on batch: 0.781250\n",
      "I0611 14:27:10.970894 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.781250\n",
      "Epoch: 0002    cost: 3.922722844 \n",
      "I0611 14:27:12.047380 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.922722844 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:27:12.048506 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.763048109 \n",
      "I0611 14:27:13.097476 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.763048109 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:13.098880 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.253979416 \n",
      "I0611 14:27:14.054760 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.253979416 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:14.055893 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0005    cost: 1.977668763 \n",
      "I0611 14:27:15.036393 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.977668763 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:15.037527 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0006    cost: 1.782017305 \n",
      "I0611 14:27:15.962181 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.782017305 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:15.963409 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0007    cost: 1.642817586 \n",
      "I0611 14:27:16.931200 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 1.642817586 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:16.932431 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0008    cost: 1.530502498 \n",
      "I0611 14:27:17.878751 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 1.530502498 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:17.880223 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0009    cost: 1.438830145 \n",
      "I0611 14:27:18.900653 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 1.438830145 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:18.901835 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0010    cost: 1.367732002 \n",
      "I0611 14:27:20.004456 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 1.367732002 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:20.005676 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0011    cost: 1.307706801 \n",
      "I0611 14:27:20.996826 4638332352 feedforward_robust.py:716] Epoch: 0011    cost: 1.307706801 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:20.998177 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0012    cost: 1.263038780 \n",
      "I0611 14:27:22.028741 4638332352 feedforward_robust.py:716] Epoch: 0012    cost: 1.263038780 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:22.030000 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0013    cost: 1.221085133 \n",
      "I0611 14:27:23.007533 4638332352 feedforward_robust.py:716] Epoch: 0013    cost: 1.221085133 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:23.008730 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0014    cost: 1.179518567 \n",
      "I0611 14:27:24.041198 4638332352 feedforward_robust.py:716] Epoch: 0014    cost: 1.179518567 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:24.042685 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0015    cost: 1.145948007 \n",
      "I0611 14:27:25.194231 4638332352 feedforward_robust.py:716] Epoch: 0015    cost: 1.145948007 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:25.195761 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0016    cost: 1.112495736 \n",
      "I0611 14:27:26.239727 4638332352 feedforward_robust.py:716] Epoch: 0016    cost: 1.112495736 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:26.240697 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0017    cost: 1.087070491 \n",
      "I0611 14:27:27.284986 4638332352 feedforward_robust.py:716] Epoch: 0017    cost: 1.087070491 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:27.286237 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0018    cost: 1.062921593 \n",
      "I0611 14:27:28.319205 4638332352 feedforward_robust.py:716] Epoch: 0018    cost: 1.062921593 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:28.320307 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0019    cost: 1.038175433 \n",
      "I0611 14:27:29.344624 4638332352 feedforward_robust.py:716] Epoch: 0019    cost: 1.038175433 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:29.345767 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0020    cost: 1.014724208 \n",
      "I0611 14:27:30.299205 4638332352 feedforward_robust.py:716] Epoch: 0020    cost: 1.014724208 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:30.300441 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0021    cost: 0.998925812 \n",
      "I0611 14:27:31.350437 4638332352 feedforward_robust.py:716] Epoch: 0021    cost: 0.998925812 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:31.351994 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0022    cost: 0.980537726 \n",
      "I0611 14:27:32.350191 4638332352 feedforward_robust.py:716] Epoch: 0022    cost: 0.980537726 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:32.351145 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0023    cost: 0.958666797 \n",
      "I0611 14:27:33.281946 4638332352 feedforward_robust.py:716] Epoch: 0023    cost: 0.958666797 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:33.283088 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0024    cost: 0.944630408 \n",
      "I0611 14:27:34.309969 4638332352 feedforward_robust.py:716] Epoch: 0024    cost: 0.944630408 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:34.311142 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0025    cost: 0.931947221 \n",
      "I0611 14:27:35.291173 4638332352 feedforward_robust.py:716] Epoch: 0025    cost: 0.931947221 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:35.292663 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0026    cost: 0.924086434 \n",
      "I0611 14:27:36.271754 4638332352 feedforward_robust.py:716] Epoch: 0026    cost: 0.924086434 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:36.273233 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0027    cost: 0.912875397 \n",
      "I0611 14:27:37.214976 4638332352 feedforward_robust.py:716] Epoch: 0027    cost: 0.912875397 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:37.216269 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0028    cost: 0.904915964 \n",
      "I0611 14:27:38.173861 4638332352 feedforward_robust.py:716] Epoch: 0028    cost: 0.904915964 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:38.175364 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0029    cost: 0.899109767 \n",
      "I0611 14:27:39.122177 4638332352 feedforward_robust.py:716] Epoch: 0029    cost: 0.899109767 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:39.123642 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0030    cost: 0.882714187 \n",
      "I0611 14:27:40.038785 4638332352 feedforward_robust.py:716] Epoch: 0030    cost: 0.882714187 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:40.040468 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Optimization Finished!\n",
      "I0611 14:27:40.043919 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.932856\n",
      "I0611 14:27:40.186693 4638332352 feedforward_robust.py:726] Final Train Loss 0.932856\n",
      "Final Train Accuracy 0.954900:\n",
      "I0611 14:27:40.195276 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.954900:\n",
      "Model was trained on benign data\n",
      "I0611 14:27:40.197379 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:40.268064 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:40.311646 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:27:40.335101 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 14:27:40.502585 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test loss and accuracy ----\n",
      "(1.2695092, 0.9485)\n",
      "----Real test loss and accuracy comparing to teacher ----\n",
      "(208.2667, 0.8521)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:27:40.519871 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----FGSM test loss and accuracy ----\n",
      "(1325.2003, 0.7636)\n",
      "iteration: 0\n",
      "loss 1.043663\n",
      "iteration: 1\n",
      "loss 2.063286\n",
      "iteration: 2\n",
      "loss 3.448260\n",
      "iteration: 3\n",
      "loss 5.007183\n",
      "iteration: 4\n",
      "loss 6.605892\n",
      "iteration: 5\n",
      "loss 8.181146\n",
      "iteration: 6\n",
      "loss 9.702505\n",
      "iteration: 7\n",
      "loss 11.152001\n",
      "iteration: 8\n",
      "loss 12.524700\n",
      "iteration: 9\n",
      "loss 13.810907\n",
      "iteration: 10\n",
      "loss 15.011579\n",
      "iteration: 11\n",
      "loss 16.122969\n",
      "iteration: 12\n",
      "loss 17.142822\n",
      "iteration: 13\n",
      "loss 18.069492\n",
      "iteration: 14\n",
      "loss 18.902082\n",
      "iteration: 15\n",
      "loss 19.641357\n",
      "iteration: 16\n",
      "loss 20.283484\n",
      "iteration: 17\n",
      "loss 20.827827\n",
      "iteration: 18\n",
      "loss 21.273535\n",
      "iteration: 19\n",
      "loss 21.621094\n",
      "iteration: 20\n",
      "loss 21.898458\n",
      "iteration: 21\n",
      "loss 22.143703\n",
      "iteration: 22\n",
      "loss 22.358238\n",
      "iteration: 23\n",
      "loss 22.544432\n",
      "iteration: 24\n",
      "loss 22.707237\n",
      "iteration: 25\n",
      "loss 22.848782\n",
      "iteration: 26\n",
      "loss 22.971888\n",
      "iteration: 27\n",
      "loss 23.080063\n",
      "iteration: 28\n",
      "loss 23.175508\n",
      "iteration: 29\n",
      "loss 23.258404\n",
      "iteration: 30\n",
      "loss 23.335562\n",
      "iteration: 31\n",
      "loss 23.403860\n",
      "iteration: 32\n",
      "loss 23.464531\n",
      "iteration: 33\n",
      "loss 23.522488\n",
      "iteration: 34\n",
      "loss 23.572340\n",
      "iteration: 35\n",
      "loss 23.621155\n",
      "iteration: 36\n",
      "loss 23.663237\n",
      "iteration: 37\n",
      "loss 23.701941\n",
      "iteration: 38\n",
      "loss 23.739609\n",
      "iteration: 39\n",
      "loss 23.773598\n",
      "iteration: 40\n",
      "loss 23.806517\n",
      "iteration: 41\n",
      "loss 23.834312\n",
      "iteration: 42\n",
      "loss 23.862207\n",
      "iteration: 43\n",
      "loss 23.887941\n",
      "iteration: 44\n",
      "loss 23.911215\n",
      "iteration: 45\n",
      "loss 23.932909\n",
      "iteration: 46\n",
      "loss 23.954529\n",
      "iteration: 47\n",
      "loss 23.975475\n",
      "iteration: 48\n",
      "loss 23.992384\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:27:45.461327 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:27:45.462692 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:27:45.506175 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 24.011793\n",
      "----PGD test loss and accuracy ----\n",
      "(683.9786, 0.0009)\n"
     ]
    }
   ],
   "source": [
    "tup = slave_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.93285626,\n",
       " 0.9549,\n",
       " 1.2695092,\n",
       " 0.9485,\n",
       " 0.8521,\n",
       " array([[ -2.4738553 ,   1.4548903 ,  -5.2864723 , ..., -16.553606  ,\n",
       "          -9.862367  , -11.722542  ],\n",
       "        [ -2.777988  ,  -0.2097955 ,  -6.139147  , ..., -11.253925  ,\n",
       "          -4.0789533 , -11.227329  ],\n",
       "        [ -7.0907645 ,  -6.7067056 ,  -8.018333  , ...,   8.033091  ,\n",
       "          -5.7001867 ,  -2.5510015 ],\n",
       "        ...,\n",
       "        [ -3.5365465 ,  -2.6542697 ,  -4.6018915 , ..., -13.083588  ,\n",
       "          -9.382924  ,  -9.573526  ],\n",
       "        [  3.6126416 ,  -5.420528  ,  -0.13431433, ..., -12.910023  ,\n",
       "          -5.582261  ,  -7.7274966 ],\n",
       "        [ -6.3852077 ,  -7.5782604 ,  -8.277701  , ...,  -3.2700589 ,\n",
       "          -9.510182  ,  -8.48611   ]], dtype=float32),\n",
       " array([[ -7.1515765 ,  -5.5476246 ,  -7.131644  , ...,   1.7403907 ,\n",
       "          -8.918869  ,   5.581065  ],\n",
       "        [ -7.2639294 , -14.082399  ,   6.8233366 , ..., -17.89693   ,\n",
       "         -11.568522  , -12.727906  ],\n",
       "        [ -5.3687563 ,  16.649733  , -16.944101  , ...,  -7.1560364 ,\n",
       "         -12.090617  , -13.448195  ],\n",
       "        ...,\n",
       "        [ -0.44599098,  -9.255183  ,  -1.6544535 , ...,  -6.32419   ,\n",
       "           8.118214  ,  -8.542353  ],\n",
       "        [ -7.0366855 ,  12.588056  , -10.776271  , ...,  -2.8055482 ,\n",
       "         -10.18191   ,  -5.438324  ],\n",
       "        [ -4.6907697 ,  -6.569682  ,  -6.450926  , ...,  -1.2722718 ,\n",
       "          -4.40865   ,  -8.228916  ]], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['mse on z_train'] = []\n",
    "df['acc on z_train'] = []\n",
    "df['mse on z_test'] = []\n",
    "df['acc on z_test'] = []\n",
    "df['acc on y_test'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:27:45.891708 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:27:45.900774 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0611 14:27:45.982398 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:27:45.989894 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:27:46.009101 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:27:46.012348 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.209017649 \n",
      "I0611 14:27:47.615728 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.209017649 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:27:47.616786 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0002    cost: 3.917461560 \n",
      "I0611 14:27:48.520066 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.917461560 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:27:48.521093 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.749678619 \n",
      "I0611 14:27:49.405025 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.749678619 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:27:49.406166 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.248680972 \n",
      "I0611 14:27:50.298635 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.248680972 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:50.299989 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0005    cost: 1.952400131 \n",
      "I0611 14:27:51.217540 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.952400131 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:51.218691 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0006    cost: 1.744025418 \n",
      "I0611 14:27:52.079259 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.744025418 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:52.080696 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0007    cost: 1.596262608 \n",
      "I0611 14:27:53.028803 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 1.596262608 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:53.031250 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0008    cost: 1.480016434 \n",
      "I0611 14:27:54.019062 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 1.480016434 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:54.021106 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0009    cost: 1.397437789 \n",
      "I0611 14:27:55.187309 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 1.397437789 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:55.188533 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0010    cost: 1.310127477 \n",
      "I0611 14:27:56.222513 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 1.310127477 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:27:56.223793 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0011    cost: 1.244151702 \n",
      "I0611 14:27:57.338630 4638332352 feedforward_robust.py:716] Epoch: 0011    cost: 1.244151702 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:57.339766 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0012    cost: 1.192086148 \n",
      "I0611 14:27:58.344254 4638332352 feedforward_robust.py:716] Epoch: 0012    cost: 1.192086148 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:58.346115 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0013    cost: 1.140497389 \n",
      "I0611 14:27:59.327431 4638332352 feedforward_robust.py:716] Epoch: 0013    cost: 1.140497389 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:27:59.328470 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0014    cost: 1.094745758 \n",
      "I0611 14:28:00.213254 4638332352 feedforward_robust.py:716] Epoch: 0014    cost: 1.094745758 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:28:00.214677 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0015    cost: 1.062556699 \n",
      "I0611 14:28:01.091934 4638332352 feedforward_robust.py:716] Epoch: 0015    cost: 1.062556699 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:28:01.093526 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0016    cost: 1.032426415 \n",
      "I0611 14:28:02.031932 4638332352 feedforward_robust.py:716] Epoch: 0016    cost: 1.032426415 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:28:02.033285 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0017    cost: 1.002116164 \n",
      "I0611 14:28:03.035923 4638332352 feedforward_robust.py:716] Epoch: 0017    cost: 1.002116164 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:03.037374 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0018    cost: 0.977076611 \n",
      "I0611 14:28:03.968644 4638332352 feedforward_robust.py:716] Epoch: 0018    cost: 0.977076611 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:03.970159 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0019    cost: 0.958430828 \n",
      "I0611 14:28:04.850378 4638332352 feedforward_robust.py:716] Epoch: 0019    cost: 0.958430828 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:04.851855 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0020    cost: 0.938197514 \n",
      "I0611 14:28:05.816059 4638332352 feedforward_robust.py:716] Epoch: 0020    cost: 0.938197514 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:05.817106 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0021    cost: 0.927383138 \n",
      "I0611 14:28:06.800130 4638332352 feedforward_robust.py:716] Epoch: 0021    cost: 0.927383138 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:06.801165 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0022    cost: 0.907024331 \n",
      "I0611 14:28:07.779160 4638332352 feedforward_robust.py:716] Epoch: 0022    cost: 0.907024331 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:07.780378 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0023    cost: 0.894129634 \n",
      "I0611 14:28:08.673870 4638332352 feedforward_robust.py:716] Epoch: 0023    cost: 0.894129634 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:08.675154 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0024    cost: 0.882782814 \n",
      "I0611 14:28:09.651628 4638332352 feedforward_robust.py:716] Epoch: 0024    cost: 0.882782814 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:09.652976 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0025    cost: 0.865818638 \n",
      "I0611 14:28:10.611038 4638332352 feedforward_robust.py:716] Epoch: 0025    cost: 0.865818638 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:10.612429 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0026    cost: 0.852832034 \n",
      "I0611 14:28:11.524030 4638332352 feedforward_robust.py:716] Epoch: 0026    cost: 0.852832034 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:11.526011 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0027    cost: 0.843932601 \n",
      "I0611 14:28:12.522008 4638332352 feedforward_robust.py:716] Epoch: 0027    cost: 0.843932601 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:12.523252 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0028    cost: 0.828729980 \n",
      "I0611 14:28:13.464040 4638332352 feedforward_robust.py:716] Epoch: 0028    cost: 0.828729980 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:13.465201 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0029    cost: 0.818764694 \n",
      "I0611 14:28:14.391415 4638332352 feedforward_robust.py:716] Epoch: 0029    cost: 0.818764694 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:14.392730 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0030    cost: 0.804197596 \n",
      "I0611 14:28:15.298981 4638332352 feedforward_robust.py:716] Epoch: 0030    cost: 0.804197596 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:15.300415 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Optimization Finished!\n",
      "I0611 14:28:15.301775 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.857293\n",
      "I0611 14:28:15.425322 4638332352 feedforward_robust.py:726] Final Train Loss 0.857293\n",
      "Final Train Accuracy 0.959167:\n",
      "I0611 14:28:15.426632 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.959167:\n",
      "Model was trained on benign data\n",
      "I0611 14:28:15.428823 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:15.496634 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:15.536639 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:15.561050 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 14:28:15.698168 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:28:15.714685 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test loss and accuracy ----\n",
      "(1.1885988, 0.9496)\n",
      "----Real test loss and accuracy comparing to teacher ----\n",
      "(208.79608, 0.8478)\n",
      "----FGSM test loss and accuracy ----\n",
      "(1362.2505, 0.742)\n",
      "iteration: 0\n",
      "loss 1.083219\n",
      "iteration: 1\n",
      "loss 2.167089\n",
      "iteration: 2\n",
      "loss 3.603489\n",
      "iteration: 3\n",
      "loss 5.179325\n",
      "iteration: 4\n",
      "loss 6.805217\n",
      "iteration: 5\n",
      "loss 8.416625\n",
      "iteration: 6\n",
      "loss 9.972460\n",
      "iteration: 7\n",
      "loss 11.456193\n",
      "iteration: 8\n",
      "loss 12.856785\n",
      "iteration: 9\n",
      "loss 14.171765\n",
      "iteration: 10\n",
      "loss 15.400415\n",
      "iteration: 11\n",
      "loss 16.543215\n",
      "iteration: 12\n",
      "loss 17.595863\n",
      "iteration: 13\n",
      "loss 18.557697\n",
      "iteration: 14\n",
      "loss 19.426062\n",
      "iteration: 15\n",
      "loss 20.197735\n",
      "iteration: 16\n",
      "loss 20.871138\n",
      "iteration: 17\n",
      "loss 21.444880\n",
      "iteration: 18\n",
      "loss 21.914690\n",
      "iteration: 19\n",
      "loss 22.279713\n",
      "iteration: 20\n",
      "loss 22.573040\n",
      "iteration: 21\n",
      "loss 22.831558\n",
      "iteration: 22\n",
      "loss 23.057901\n",
      "iteration: 23\n",
      "loss 23.254999\n",
      "iteration: 24\n",
      "loss 23.428110\n",
      "iteration: 25\n",
      "loss 23.580078\n",
      "iteration: 26\n",
      "loss 23.714197\n",
      "iteration: 27\n",
      "loss 23.830038\n",
      "iteration: 28\n",
      "loss 23.937408\n",
      "iteration: 29\n",
      "loss 24.029531\n",
      "iteration: 30\n",
      "loss 24.113491\n",
      "iteration: 31\n",
      "loss 24.187418\n",
      "iteration: 32\n",
      "loss 24.256027\n",
      "iteration: 33\n",
      "loss 24.316198\n",
      "iteration: 34\n",
      "loss 24.372545\n",
      "iteration: 35\n",
      "loss 24.421835\n",
      "iteration: 36\n",
      "loss 24.468838\n",
      "iteration: 37\n",
      "loss 24.511127\n",
      "iteration: 38\n",
      "loss 24.552759\n",
      "iteration: 39\n",
      "loss 24.587969\n",
      "iteration: 40\n",
      "loss 24.623480\n",
      "iteration: 41\n",
      "loss 24.655540\n",
      "iteration: 42\n",
      "loss 24.686102\n",
      "iteration: 43\n",
      "loss 24.712696\n",
      "iteration: 44\n",
      "loss 24.741743\n",
      "iteration: 45\n",
      "loss 24.765009\n",
      "iteration: 46\n",
      "loss 24.787989\n",
      "iteration: 47\n",
      "loss 24.809597\n",
      "iteration: 48\n",
      "loss 24.830162\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:28:20.914702 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:28:20.916465 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:28:20.971352 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 24.849209\n",
      "----PGD test loss and accuracy ----\n",
      "(723.0785, 0.003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 14:28:21.212563 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:28:21.221371 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n",
      "Created layers and tensor for logits\n",
      "I0611 14:28:21.276872 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:28:21.283307 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:28:21.294542 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:28:21.295874 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.464040700 \n",
      "I0611 14:28:23.039726 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.464040700 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 14:28:23.040753 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0002    cost: 3.701160542 \n",
      "I0611 14:28:24.017629 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.701160542 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:28:24.019115 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.655647429 \n",
      "I0611 14:28:24.903921 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.655647429 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:24.905468 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.176999009 \n",
      "I0611 14:28:25.798273 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.176999009 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:25.799550 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0005    cost: 1.892996802 \n",
      "I0611 14:28:26.698386 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.892996802 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:26.699866 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0006    cost: 1.689311388 \n",
      "I0611 14:28:27.630409 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.689311388 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:27.631635 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0007    cost: 1.544143264 \n",
      "I0611 14:28:28.535705 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 1.544143264 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:28.536901 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0008    cost: 1.424002259 \n",
      "I0611 14:28:29.398058 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 1.424002259 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:29.399516 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0009    cost: 1.338921389 \n",
      "I0611 14:28:30.292559 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 1.338921389 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:30.294118 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0010    cost: 1.265167956 \n",
      "I0611 14:28:31.178508 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 1.265167956 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:31.179767 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0011    cost: 1.204088457 \n",
      "I0611 14:28:32.157200 4638332352 feedforward_robust.py:716] Epoch: 0011    cost: 1.204088457 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:32.158799 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0012    cost: 1.155839224 \n",
      "I0611 14:28:33.199730 4638332352 feedforward_robust.py:716] Epoch: 0012    cost: 1.155839224 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:33.200757 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0013    cost: 1.113152679 \n",
      "I0611 14:28:34.069499 4638332352 feedforward_robust.py:716] Epoch: 0013    cost: 1.113152679 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:34.070716 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0014    cost: 1.076100684 \n",
      "I0611 14:28:34.958830 4638332352 feedforward_robust.py:716] Epoch: 0014    cost: 1.076100684 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:34.960240 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0015    cost: 1.042052156 \n",
      "I0611 14:28:35.887201 4638332352 feedforward_robust.py:716] Epoch: 0015    cost: 1.042052156 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:35.888581 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0016    cost: 1.009398851 \n",
      "I0611 14:28:36.724443 4638332352 feedforward_robust.py:716] Epoch: 0016    cost: 1.009398851 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:36.725637 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0017    cost: 0.984686764 \n",
      "I0611 14:28:37.590960 4638332352 feedforward_robust.py:716] Epoch: 0017    cost: 0.984686764 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:37.592149 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0018    cost: 0.958575838 \n",
      "I0611 14:28:38.871639 4638332352 feedforward_robust.py:716] Epoch: 0018    cost: 0.958575838 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:28:38.873061 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0019    cost: 0.945640166 \n",
      "I0611 14:28:40.445029 4638332352 feedforward_robust.py:716] Epoch: 0019    cost: 0.945640166 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:40.446483 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0020    cost: 0.920574669 \n",
      "I0611 14:28:41.642565 4638332352 feedforward_robust.py:716] Epoch: 0020    cost: 0.920574669 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:41.643939 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0021    cost: 0.906226928 \n",
      "I0611 14:28:42.587623 4638332352 feedforward_robust.py:716] Epoch: 0021    cost: 0.906226928 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:42.590323 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0022    cost: 0.894094440 \n",
      "I0611 14:28:43.542562 4638332352 feedforward_robust.py:716] Epoch: 0022    cost: 0.894094440 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:43.543792 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0023    cost: 0.885742435 \n",
      "I0611 14:28:44.461997 4638332352 feedforward_robust.py:716] Epoch: 0023    cost: 0.885742435 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:44.463279 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0024    cost: 0.877703457 \n",
      "I0611 14:28:45.355734 4638332352 feedforward_robust.py:716] Epoch: 0024    cost: 0.877703457 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:45.356835 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0025    cost: 0.864741175 \n",
      "I0611 14:28:46.259310 4638332352 feedforward_robust.py:716] Epoch: 0025    cost: 0.864741175 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:46.260469 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0026    cost: 0.850745084 \n",
      "I0611 14:28:47.295608 4638332352 feedforward_robust.py:716] Epoch: 0026    cost: 0.850745084 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:47.296944 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0027    cost: 0.838138269 \n",
      "I0611 14:28:48.477924 4638332352 feedforward_robust.py:716] Epoch: 0027    cost: 0.838138269 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:48.479228 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0028    cost: 0.827780337 \n",
      "I0611 14:28:49.433790 4638332352 feedforward_robust.py:716] Epoch: 0028    cost: 0.827780337 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:49.435030 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0029    cost: 0.824610350 \n",
      "I0611 14:28:50.359147 4638332352 feedforward_robust.py:716] Epoch: 0029    cost: 0.824610350 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:50.360488 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0030    cost: 0.818497846 \n",
      "I0611 14:28:51.272403 4638332352 feedforward_robust.py:716] Epoch: 0030    cost: 0.818497846 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:28:51.276681 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Optimization Finished!\n",
      "I0611 14:28:51.279903 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.848339\n",
      "I0611 14:28:51.449861 4638332352 feedforward_robust.py:726] Final Train Loss 0.848339\n",
      "Final Train Accuracy 0.957467:\n",
      "I0611 14:28:51.451256 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.957467:\n",
      "Model was trained on benign data\n",
      "I0611 14:28:51.453786 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:51.536632 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:51.577103 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:28:51.598079 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model is being evaluated on FGSM data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 14:28:51.747745 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:28:51.768181 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test loss and accuracy ----\n",
      "(1.1803124, 0.9474)\n",
      "----Real test loss and accuracy comparing to teacher ----\n",
      "(210.34569, 0.8528)\n",
      "----FGSM test loss and accuracy ----\n",
      "(1379.572, 0.7677)\n",
      "iteration: 0\n",
      "loss 1.030054\n",
      "iteration: 1\n",
      "loss 2.065170\n",
      "iteration: 2\n",
      "loss 3.473079\n",
      "iteration: 3\n",
      "loss 5.057021\n",
      "iteration: 4\n",
      "loss 6.697995\n",
      "iteration: 5\n",
      "loss 8.331947\n",
      "iteration: 6\n",
      "loss 9.909674\n",
      "iteration: 7\n",
      "loss 11.418397\n",
      "iteration: 8\n",
      "loss 12.847183\n",
      "iteration: 9\n",
      "loss 14.188484\n",
      "iteration: 10\n",
      "loss 15.437018\n",
      "iteration: 11\n",
      "loss 16.592808\n",
      "iteration: 12\n",
      "loss 17.654598\n",
      "iteration: 13\n",
      "loss 18.618382\n",
      "iteration: 14\n",
      "loss 19.485189\n",
      "iteration: 15\n",
      "loss 20.254896\n",
      "iteration: 16\n",
      "loss 20.922251\n",
      "iteration: 17\n",
      "loss 21.488312\n",
      "iteration: 18\n",
      "loss 21.946346\n",
      "iteration: 19\n",
      "loss 22.298000\n",
      "iteration: 20\n",
      "loss 22.577328\n",
      "iteration: 21\n",
      "loss 22.822159\n",
      "iteration: 22\n",
      "loss 23.033497\n",
      "iteration: 23\n",
      "loss 23.217615\n",
      "iteration: 24\n",
      "loss 23.376165\n",
      "iteration: 25\n",
      "loss 23.513409\n",
      "iteration: 26\n",
      "loss 23.635120\n",
      "iteration: 27\n",
      "loss 23.741625\n",
      "iteration: 28\n",
      "loss 23.834965\n",
      "iteration: 29\n",
      "loss 23.920496\n",
      "iteration: 30\n",
      "loss 23.997490\n",
      "iteration: 31\n",
      "loss 24.068287\n",
      "iteration: 32\n",
      "loss 24.131897\n",
      "iteration: 33\n",
      "loss 24.190702\n",
      "iteration: 34\n",
      "loss 24.244179\n",
      "iteration: 35\n",
      "loss 24.295315\n",
      "iteration: 36\n",
      "loss 24.341228\n",
      "iteration: 37\n",
      "loss 24.386328\n",
      "iteration: 38\n",
      "loss 24.426813\n",
      "iteration: 39\n",
      "loss 24.465824\n",
      "iteration: 40\n",
      "loss 24.502378\n",
      "iteration: 41\n",
      "loss 24.537827\n",
      "iteration: 42\n",
      "loss 24.572010\n",
      "iteration: 43\n",
      "loss 24.605118\n",
      "iteration: 44\n",
      "loss 24.635412\n",
      "iteration: 45\n",
      "loss 24.664454\n",
      "iteration: 46\n",
      "loss 24.691710\n",
      "iteration: 47\n",
      "loss 24.718380\n",
      "iteration: 48\n",
      "loss 24.742990\n",
      "iteration: 49\n",
      "loss 24.766394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:28:56.603441 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:28:56.604606 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:28:56.646888 4638332352 feedforward_robust.py:498] 0.10000005352730845\n",
      "Initialized instance variables of the robust model class\n",
      "I0611 14:28:56.819741 4638332352 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "Created placeholders for x and y\n",
      "I0611 14:28:56.826439 4638332352 feedforward_robust.py:40] Created placeholders for x and y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----PGD test loss and accuracy ----\n",
      "(743.3106, 0.0009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created layers and tensor for logits\n",
      "I0611 14:28:56.884889 4638332352 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 14:28:56.892559 4638332352 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "Added MSE loss computation to the graph\n",
      "I0611 14:28:56.901700 4638332352 feedforward_robust.py:60] Added MSE loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 14:28:56.902801 4638332352 feedforward_robust.py:62] Model graph was created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0001    cost: 17.017065522 \n",
      "I0611 14:28:58.437588 4638332352 feedforward_robust.py:716] Epoch: 0001    cost: 17.017065522 \n",
      "Accuracy on batch: 0.812500\n",
      "I0611 14:28:58.438688 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.812500\n",
      "Epoch: 0002    cost: 3.754789643 \n",
      "I0611 14:28:59.315710 4638332352 feedforward_robust.py:716] Epoch: 0002    cost: 3.754789643 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 14:28:59.317146 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0003    cost: 2.623002093 \n",
      "I0611 14:29:00.172679 4638332352 feedforward_robust.py:716] Epoch: 0003    cost: 2.623002093 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:00.173903 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0004    cost: 2.120013815 \n",
      "I0611 14:29:01.089090 4638332352 feedforward_robust.py:716] Epoch: 0004    cost: 2.120013815 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:01.090659 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0005    cost: 1.849083787 \n",
      "I0611 14:29:02.062116 4638332352 feedforward_robust.py:716] Epoch: 0005    cost: 1.849083787 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:02.066540 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0006    cost: 1.671587121 \n",
      "I0611 14:29:03.030693 4638332352 feedforward_robust.py:716] Epoch: 0006    cost: 1.671587121 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:03.032352 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0007    cost: 1.546408840 \n",
      "I0611 14:29:03.966430 4638332352 feedforward_robust.py:716] Epoch: 0007    cost: 1.546408840 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:03.967807 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0008    cost: 1.440994471 \n",
      "I0611 14:29:05.091809 4638332352 feedforward_robust.py:716] Epoch: 0008    cost: 1.440994471 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:05.092976 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0009    cost: 1.353721950 \n",
      "I0611 14:29:06.207755 4638332352 feedforward_robust.py:716] Epoch: 0009    cost: 1.353721950 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:06.208848 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0010    cost: 1.291140035 \n",
      "I0611 14:29:07.355901 4638332352 feedforward_robust.py:716] Epoch: 0010    cost: 1.291140035 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:07.357022 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0011    cost: 1.232289592 \n",
      "I0611 14:29:08.276693 4638332352 feedforward_robust.py:716] Epoch: 0011    cost: 1.232289592 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:08.278635 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0012    cost: 1.186502698 \n",
      "I0611 14:29:09.242368 4638332352 feedforward_robust.py:716] Epoch: 0012    cost: 1.186502698 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:09.243502 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0013    cost: 1.146024251 \n",
      "I0611 14:29:10.231925 4638332352 feedforward_robust.py:716] Epoch: 0013    cost: 1.146024251 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:10.233434 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0014    cost: 1.102449927 \n",
      "I0611 14:29:11.140785 4638332352 feedforward_robust.py:716] Epoch: 0014    cost: 1.102449927 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:11.141996 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0015    cost: 1.074654940 \n",
      "I0611 14:29:12.151288 4638332352 feedforward_robust.py:716] Epoch: 0015    cost: 1.074654940 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:12.152651 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0016    cost: 1.046605923 \n",
      "I0611 14:29:13.383042 4638332352 feedforward_robust.py:716] Epoch: 0016    cost: 1.046605923 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:13.384970 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0017    cost: 1.022409809 \n",
      "I0611 14:29:14.704606 4638332352 feedforward_robust.py:716] Epoch: 0017    cost: 1.022409809 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:14.706152 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0018    cost: 1.003196926 \n",
      "I0611 14:29:16.015493 4638332352 feedforward_robust.py:716] Epoch: 0018    cost: 1.003196926 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 14:29:16.016930 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0019    cost: 0.987824994 \n",
      "I0611 14:29:17.124659 4638332352 feedforward_robust.py:716] Epoch: 0019    cost: 0.987824994 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:29:17.126208 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0020    cost: 0.961624065 \n",
      "I0611 14:29:18.229307 4638332352 feedforward_robust.py:716] Epoch: 0020    cost: 0.961624065 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:29:18.230435 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0021    cost: 0.951440063 \n",
      "I0611 14:29:19.393908 4638332352 feedforward_robust.py:716] Epoch: 0021    cost: 0.951440063 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:29:19.395395 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0022    cost: 0.932832188 \n",
      "I0611 14:29:20.618288 4638332352 feedforward_robust.py:716] Epoch: 0022    cost: 0.932832188 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 14:29:20.619653 4638332352 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0023    cost: 0.921778388 \n",
      "I0611 14:29:21.865577 4638332352 feedforward_robust.py:716] Epoch: 0023    cost: 0.921778388 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:21.866945 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0024    cost: 0.912558840 \n",
      "I0611 14:29:22.992682 4638332352 feedforward_robust.py:716] Epoch: 0024    cost: 0.912558840 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:22.994292 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0025    cost: 0.919085641 \n",
      "I0611 14:29:24.144500 4638332352 feedforward_robust.py:716] Epoch: 0025    cost: 0.919085641 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:24.146157 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0026    cost: 0.890159386 \n",
      "I0611 14:29:25.378567 4638332352 feedforward_robust.py:716] Epoch: 0026    cost: 0.890159386 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:25.380266 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0027    cost: 0.874311540 \n",
      "I0611 14:29:26.477633 4638332352 feedforward_robust.py:716] Epoch: 0027    cost: 0.874311540 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:26.479526 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0028    cost: 0.852675930 \n",
      "I0611 14:29:27.728785 4638332352 feedforward_robust.py:716] Epoch: 0028    cost: 0.852675930 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:27.776240 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0029    cost: 0.836444558 \n",
      "I0611 14:29:29.951308 4638332352 feedforward_robust.py:716] Epoch: 0029    cost: 0.836444558 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:29.957541 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0030    cost: 0.824178470 \n",
      "I0611 14:29:31.915589 4638332352 feedforward_robust.py:716] Epoch: 0030    cost: 0.824178470 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 14:29:31.919034 4638332352 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Optimization Finished!\n",
      "I0611 14:29:31.922276 4638332352 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 0.893602\n",
      "I0611 14:29:32.293029 4638332352 feedforward_robust.py:726] Final Train Loss 0.893602\n",
      "Final Train Accuracy 0.956600:\n",
      "I0611 14:29:32.311919 4638332352 feedforward_robust.py:727] Final Train Accuracy 0.956600:\n",
      "Model was trained on benign data\n",
      "I0611 14:29:32.338057 4638332352 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:29:32.452105 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:29:32.635504 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 14:29:32.668276 4638332352 feedforward_robust.py:642] Model was evaluated on benign data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Regular test loss and accuracy ----\n",
      "(1.2153168, 0.948)\n",
      "----Real test loss and accuracy comparing to teacher ----\n",
      "(210.90607, 0.8487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is being evaluated on FGSM data\n",
      "I0611 14:29:32.968237 4638332352 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 14:29:32.990973 4638332352 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----FGSM test loss and accuracy ----\n",
      "(1383.2758, 0.7486)\n",
      "iteration: 0\n",
      "loss 1.070831\n",
      "iteration: 1\n",
      "loss 2.113897\n",
      "iteration: 2\n",
      "loss 3.527900\n",
      "iteration: 3\n",
      "loss 5.130661\n",
      "iteration: 4\n",
      "loss 6.776577\n",
      "iteration: 5\n",
      "loss 8.409399\n",
      "iteration: 6\n",
      "loss 9.991628\n",
      "iteration: 7\n",
      "loss 11.502928\n",
      "iteration: 8\n",
      "loss 12.936400\n",
      "iteration: 9\n",
      "loss 14.281739\n",
      "iteration: 10\n",
      "loss 15.537941\n",
      "iteration: 11\n",
      "loss 16.703398\n",
      "iteration: 12\n",
      "loss 17.777176\n",
      "iteration: 13\n",
      "loss 18.757233\n",
      "iteration: 14\n",
      "loss 19.640596\n",
      "iteration: 15\n",
      "loss 20.423594\n",
      "iteration: 16\n",
      "loss 21.107849\n",
      "iteration: 17\n",
      "loss 21.686428\n",
      "iteration: 18\n",
      "loss 22.157909\n",
      "iteration: 19\n",
      "loss 22.521212\n",
      "iteration: 20\n",
      "loss 22.814095\n",
      "iteration: 21\n",
      "loss 23.070210\n",
      "iteration: 22\n",
      "loss 23.296171\n",
      "iteration: 23\n",
      "loss 23.493986\n",
      "iteration: 24\n",
      "loss 23.665503\n",
      "iteration: 25\n",
      "loss 23.817781\n",
      "iteration: 26\n",
      "loss 23.949539\n",
      "iteration: 27\n",
      "loss 24.068150\n",
      "iteration: 28\n",
      "loss 24.169683\n",
      "iteration: 29\n",
      "loss 24.262922\n",
      "iteration: 30\n",
      "loss 24.342882\n",
      "iteration: 31\n",
      "loss 24.417074\n",
      "iteration: 32\n",
      "loss 24.482290\n",
      "iteration: 33\n",
      "loss 24.541965\n",
      "iteration: 34\n",
      "loss 24.595966\n",
      "iteration: 35\n",
      "loss 24.646423\n",
      "iteration: 36\n",
      "loss 24.692368\n",
      "iteration: 37\n",
      "loss 24.734810\n",
      "iteration: 38\n",
      "loss 24.773775\n",
      "iteration: 39\n",
      "loss 24.810621\n",
      "iteration: 40\n",
      "loss 24.844662\n",
      "iteration: 41\n",
      "loss 24.877110\n",
      "iteration: 42\n",
      "loss 24.905388\n",
      "iteration: 43\n",
      "loss 24.933550\n",
      "iteration: 44\n",
      "loss 24.959551\n",
      "iteration: 45\n",
      "loss 24.983654\n",
      "iteration: 46\n",
      "loss 25.005585\n",
      "iteration: 47\n",
      "loss 25.026594\n",
      "iteration: 48\n",
      "loss 25.046722\n",
      "iteration: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 14:29:40.541026 4638332352 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 14:29:40.542710 4638332352 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 14:29:40.592694 4638332352 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 25.065372\n",
      "----PGD test loss and accuracy ----\n",
      "(736.89136, 0.0021)\n"
     ]
    }
   ],
   "source": [
    "train_confidences = []\n",
    "test_confidences = []\n",
    "for i in range(3):\n",
    "    loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg, slave_train_confidences, slave_test_confidences = slave_training()\n",
    "    df.loc[i] = [loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg]\n",
    "    train_confidences.append(slave_train_confidences)\n",
    "    test_confidences.append(slave_test_confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse on z_train</th>\n",
       "      <th>acc on z_train</th>\n",
       "      <th>mse on z_test</th>\n",
       "      <th>acc on z_test</th>\n",
       "      <th>acc on y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857293</td>\n",
       "      <td>0.959167</td>\n",
       "      <td>1.188599</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>0.8478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.848339</td>\n",
       "      <td>0.957467</td>\n",
       "      <td>1.180312</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.893602</td>\n",
       "      <td>0.956600</td>\n",
       "      <td>1.215317</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.8487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mse on z_train  acc on z_train  mse on z_test  acc on z_test  acc on y_test\n",
       "0        0.857293        0.959167       1.188599         0.9496         0.8478\n",
       "1        0.848339        0.957467       1.180312         0.9474         0.8528\n",
       "2        0.893602        0.956600       1.215317         0.9480         0.8487"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"ts_fashion_results.xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
