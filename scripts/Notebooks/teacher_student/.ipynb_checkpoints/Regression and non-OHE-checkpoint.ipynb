{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 18:10:02.297460 4393846208 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import logging\n",
    "import os, random, time, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import ipdb\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../../')\n",
    "import feedforward_robust as ffr\n",
    "\n",
    "sys.path.append('../../../utils/')\n",
    "from utils.mnist_corruption import *\n",
    "from utils.utils_models import *\n",
    "from utils.utils_analysis import *\n",
    "from utils.utils_feedforward import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Read the counter\n",
    "ctr_file = \"../../counter.txt\"\n",
    "f = open(ctr_file, 'r')\n",
    "counter = f.readline()\n",
    "f.close()\n",
    "\n",
    "counter = 1 + int(counter)\n",
    "f = open(ctr_file,'w')\n",
    "f.write('{}'.format(counter))\n",
    "f.close()\n",
    "logfile = \"../../logs/results_\" + str(counter) + \".log\"\n",
    "\n",
    "logger = logging.getLogger(\"robustness\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler(logfile)\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Fashion MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot the labels\n",
    "num_classes = 10\n",
    "y_train_oh = keras.utils.to_categorical(y_train, num_classes)                                                                                         \n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 0.2\n",
    "y_train_oh = y_train_oh * max_val\n",
    "remainder = (1 - max_val)/9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08888888888888889"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = np.ones(y_train_oh.shape)\n",
    "for i in range(len(y_train_oh)):\n",
    "    correct_index = y_train[i]\n",
    "    to_add[i, correct_index] = 0\n",
    "to_add = to_add * remainder\n",
    "y_train_oh = y_train_oh + to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_master, y_train_master = x_train[:30000], y_train[:30000]\n",
    "x_train_slave, y_train_slave = x_train[30000:], y_train[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten everything\n",
    "x_train_master_flat, input_shape = flatten_mnist(x_train_master) \n",
    "x_train_slave_flat, _ = flatten_mnist(x_train_slave)\n",
    "x_test_flat, _  = flatten_mnist(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "eps_train = 0.1                                                                                                                            \n",
    "eps_test = 0.1                                                                                                                             \n",
    "tensorboard_dir = \"../tb/\"                                                                                                                \n",
    "weights_dir = \"../weights/\"                                                                                                               \n",
    "load_weights = False                                                                                                              \n",
    "load_counter = 234                                                                                                            \n",
    "sigma = tf.nn.relu                                                                                                                         \n",
    "epochs, reg, lr = 100, 0.00, 1e-3    \n",
    "#epochs, reg, lr = 30, 0.00, 15e-4                                                                                                          \n",
    "pgd_eta, pgd_num_iter = 1e-2, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized instance variables of the robust model class\n",
      "I0611 18:10:03.840367 4393846208 feedforward_robust.py:32] Initialized instance variables of the robust model class\n",
      "W0611 18:10:03.844049 4393846208 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:36: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Created placeholders for x and y\n",
      "I0611 18:10:03.856899 4393846208 feedforward_robust.py:40] Created placeholders for x and y\n",
      "W0611 18:10:03.858345 4393846208 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:34: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0611 18:10:03.859033 4393846208 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:34: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0611 18:10:03.860620 4393846208 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:36: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0611 18:10:03.876477 4393846208 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:40: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "Created layers and tensor for logits\n",
      "I0611 18:10:03.933964 4393846208 feedforward_robust.py:44] Created layers and tensor for logits\n",
      "Added accuracy computation to the graph\n",
      "I0611 18:10:03.948248 4393846208 feedforward_robust.py:48] Added accuracy computation to the graph\n",
      "W0611 18:10:03.954546 4393846208 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:49: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0611 18:10:03.958060 4393846208 deprecation.py:323] From ../../../feedforward_robust.py:53: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Added cross-entropy loss computation to the graph\n",
      "I0611 18:10:03.995850 4393846208 feedforward_robust.py:56] Added cross-entropy loss computation to the graph\n",
      "Model graph was created\n",
      "I0611 18:10:03.997513 4393846208 feedforward_robust.py:62] Model graph was created\n",
      "W0611 18:10:03.999842 4393846208 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:63: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0611 18:10:04.045768 4393846208 deprecation_wrapper.py:119] From ../../../utils/utils_feedforward.py:78: The name tf.linalg.transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n",
      "\n",
      "W0611 18:10:04.103106 4393846208 deprecation.py:323] From ../../../feedforward_robust.py:739: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "W0611 18:10:04.103770 4393846208 deprecation_wrapper.py:119] From ../../../feedforward_robust.py:740: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model successfully. Now going to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 18:10:04.570297 4393846208 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n",
      "Epoch: 0001    cost: 2.274303485 \n",
      "I0611 18:10:05.999381 4393846208 feedforward_robust.py:716] Epoch: 0001    cost: 2.274303485 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 18:10:06.001448 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0002    cost: 2.268948558 \n",
      "I0611 18:10:07.102023 4393846208 feedforward_robust.py:716] Epoch: 0002    cost: 2.268948558 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 18:10:07.103872 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0003    cost: 2.267758763 \n",
      "I0611 18:10:08.224104 4393846208 feedforward_robust.py:716] Epoch: 0003    cost: 2.267758763 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:08.225656 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0004    cost: 2.267035628 \n",
      "I0611 18:10:09.310188 4393846208 feedforward_robust.py:716] Epoch: 0004    cost: 2.267035628 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 18:10:09.311923 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0005    cost: 2.266509048 \n",
      "I0611 18:10:10.395505 4393846208 feedforward_robust.py:716] Epoch: 0005    cost: 2.266509048 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 18:10:10.397178 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0006    cost: 2.266098961 \n",
      "I0611 18:10:11.855315 4393846208 feedforward_robust.py:716] Epoch: 0006    cost: 2.266098961 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 18:10:11.857428 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0007    cost: 2.265909230 \n",
      "I0611 18:10:13.209935 4393846208 feedforward_robust.py:716] Epoch: 0007    cost: 2.265909230 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:13.211522 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0008    cost: 2.265592544 \n",
      "I0611 18:10:14.319612 4393846208 feedforward_robust.py:716] Epoch: 0008    cost: 2.265592544 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:14.321542 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0009    cost: 2.265299285 \n",
      "I0611 18:10:15.429100 4393846208 feedforward_robust.py:716] Epoch: 0009    cost: 2.265299285 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:15.431043 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0010    cost: 2.265143647 \n",
      "I0611 18:10:16.520149 4393846208 feedforward_robust.py:716] Epoch: 0010    cost: 2.265143647 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:16.522033 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0011    cost: 2.264976625 \n",
      "I0611 18:10:17.708858 4393846208 feedforward_robust.py:716] Epoch: 0011    cost: 2.264976625 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:17.711596 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0012    cost: 2.264770288 \n",
      "I0611 18:10:18.953794 4393846208 feedforward_robust.py:716] Epoch: 0012    cost: 2.264770288 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:18.955626 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0013    cost: 2.264626979 \n",
      "I0611 18:10:20.325237 4393846208 feedforward_robust.py:716] Epoch: 0013    cost: 2.264626979 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:20.328459 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0014    cost: 2.264442540 \n",
      "I0611 18:10:21.630792 4393846208 feedforward_robust.py:716] Epoch: 0014    cost: 2.264442540 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:10:21.632580 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0015    cost: 2.264329157 \n",
      "I0611 18:10:22.853135 4393846208 feedforward_robust.py:716] Epoch: 0015    cost: 2.264329157 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:22.855213 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0016    cost: 2.264272208 \n",
      "I0611 18:10:24.007317 4393846208 feedforward_robust.py:716] Epoch: 0016    cost: 2.264272208 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:24.009542 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0017    cost: 2.264123420 \n",
      "I0611 18:10:25.209628 4393846208 feedforward_robust.py:716] Epoch: 0017    cost: 2.264123420 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:25.211372 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0018    cost: 2.264041444 \n",
      "I0611 18:10:26.366970 4393846208 feedforward_robust.py:716] Epoch: 0018    cost: 2.264041444 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:10:26.371804 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0019    cost: 2.263885274 \n",
      "I0611 18:10:27.584729 4393846208 feedforward_robust.py:716] Epoch: 0019    cost: 2.263885274 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:27.586905 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0020    cost: 2.263876187 \n",
      "I0611 18:10:28.847682 4393846208 feedforward_robust.py:716] Epoch: 0020    cost: 2.263876187 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:10:28.850166 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0021    cost: 2.263793385 \n",
      "I0611 18:10:30.086866 4393846208 feedforward_robust.py:716] Epoch: 0021    cost: 2.263793385 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:10:30.088824 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0022    cost: 2.263669979 \n",
      "I0611 18:10:31.325671 4393846208 feedforward_robust.py:716] Epoch: 0022    cost: 2.263669979 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:31.327837 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0023    cost: 2.263553718 \n",
      "I0611 18:10:32.494932 4393846208 feedforward_robust.py:716] Epoch: 0023    cost: 2.263553718 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:10:32.496400 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0024    cost: 2.263520508 \n",
      "I0611 18:10:33.716794 4393846208 feedforward_robust.py:716] Epoch: 0024    cost: 2.263520508 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:33.721173 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0025    cost: 2.263342865 \n",
      "I0611 18:10:34.948912 4393846208 feedforward_robust.py:716] Epoch: 0025    cost: 2.263342865 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:34.952898 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0026    cost: 2.263407369 \n",
      "I0611 18:10:36.087172 4393846208 feedforward_robust.py:716] Epoch: 0026    cost: 2.263407369 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:36.088850 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0027    cost: 2.263304006 \n",
      "I0611 18:10:37.144041 4393846208 feedforward_robust.py:716] Epoch: 0027    cost: 2.263304006 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:37.145770 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0028    cost: 2.263245113 \n",
      "I0611 18:10:38.205128 4393846208 feedforward_robust.py:716] Epoch: 0028    cost: 2.263245113 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:38.206819 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0029    cost: 2.263179202 \n",
      "I0611 18:10:39.273616 4393846208 feedforward_robust.py:716] Epoch: 0029    cost: 2.263179202 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 18:10:39.275013 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0030    cost: 2.263021590 \n",
      "I0611 18:10:40.537607 4393846208 feedforward_robust.py:716] Epoch: 0030    cost: 2.263021590 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:40.542510 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0031    cost: 2.263010587 \n",
      "I0611 18:10:41.822162 4393846208 feedforward_robust.py:716] Epoch: 0031    cost: 2.263010587 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:41.827505 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0032    cost: 2.262995448 \n",
      "I0611 18:10:43.102976 4393846208 feedforward_robust.py:716] Epoch: 0032    cost: 2.262995448 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:43.104623 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0033    cost: 2.262872446 \n",
      "I0611 18:10:44.708465 4393846208 feedforward_robust.py:716] Epoch: 0033    cost: 2.262872446 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:44.712272 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0034    cost: 2.262851099 \n",
      "I0611 18:10:46.218579 4393846208 feedforward_robust.py:716] Epoch: 0034    cost: 2.262851099 \n",
      "Accuracy on batch: 0.875000\n",
      "I0611 18:10:46.220253 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.875000\n",
      "Epoch: 0035    cost: 2.262796008 \n",
      "I0611 18:10:47.488276 4393846208 feedforward_robust.py:716] Epoch: 0035    cost: 2.262796008 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:47.491799 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0036    cost: 2.262823763 \n",
      "I0611 18:10:48.653672 4393846208 feedforward_robust.py:716] Epoch: 0036    cost: 2.262823763 \n",
      "Accuracy on batch: 0.843750\n",
      "I0611 18:10:48.657068 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.843750\n",
      "Epoch: 0037    cost: 2.262720877 \n",
      "I0611 18:10:49.947056 4393846208 feedforward_robust.py:716] Epoch: 0037    cost: 2.262720877 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:49.952269 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0038    cost: 2.262604007 \n",
      "I0611 18:10:51.305224 4393846208 feedforward_robust.py:716] Epoch: 0038    cost: 2.262604007 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:51.306929 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0039    cost: 2.262603404 \n",
      "I0611 18:10:52.556936 4393846208 feedforward_robust.py:716] Epoch: 0039    cost: 2.262603404 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:52.558876 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0040    cost: 2.262597900 \n",
      "I0611 18:10:53.766938 4393846208 feedforward_robust.py:716] Epoch: 0040    cost: 2.262597900 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:53.768214 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0041    cost: 2.262607157 \n",
      "I0611 18:10:54.937894 4393846208 feedforward_robust.py:716] Epoch: 0041    cost: 2.262607157 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:54.939829 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0042    cost: 2.262461500 \n",
      "I0611 18:10:56.202941 4393846208 feedforward_robust.py:716] Epoch: 0042    cost: 2.262461500 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:10:56.206600 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0043    cost: 2.262392406 \n",
      "I0611 18:10:57.587869 4393846208 feedforward_robust.py:716] Epoch: 0043    cost: 2.262392406 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:57.589638 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0044    cost: 2.262435118 \n",
      "I0611 18:10:58.947874 4393846208 feedforward_robust.py:716] Epoch: 0044    cost: 2.262435118 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:10:58.949984 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0045    cost: 2.262379396 \n",
      "I0611 18:11:00.186784 4393846208 feedforward_robust.py:716] Epoch: 0045    cost: 2.262379396 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:00.193860 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0046    cost: 2.262324241 \n",
      "I0611 18:11:01.414348 4393846208 feedforward_robust.py:716] Epoch: 0046    cost: 2.262324241 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:01.416065 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0047    cost: 2.262313895 \n",
      "I0611 18:11:02.596745 4393846208 feedforward_robust.py:716] Epoch: 0047    cost: 2.262313895 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:02.598279 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0048    cost: 2.262298037 \n",
      "I0611 18:11:03.798829 4393846208 feedforward_robust.py:716] Epoch: 0048    cost: 2.262298037 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:03.803682 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0049    cost: 2.262210166 \n",
      "I0611 18:11:05.119421 4393846208 feedforward_robust.py:716] Epoch: 0049    cost: 2.262210166 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:11:05.129683 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0050    cost: 2.262301872 \n",
      "I0611 18:11:06.529063 4393846208 feedforward_robust.py:716] Epoch: 0050    cost: 2.262301872 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:11:06.530751 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0051    cost: 2.262214633 \n",
      "I0611 18:11:07.877978 4393846208 feedforward_robust.py:716] Epoch: 0051    cost: 2.262214633 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:11:07.879167 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0052    cost: 2.262167546 \n",
      "I0611 18:11:09.014719 4393846208 feedforward_robust.py:716] Epoch: 0052    cost: 2.262167546 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:09.016346 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0053    cost: 2.262235279 \n",
      "I0611 18:11:10.191409 4393846208 feedforward_robust.py:716] Epoch: 0053    cost: 2.262235279 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:11:10.193917 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0054    cost: 2.262129461 \n",
      "I0611 18:11:11.432824 4393846208 feedforward_robust.py:716] Epoch: 0054    cost: 2.262129461 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:11.434648 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0055    cost: 2.262097307 \n",
      "I0611 18:11:12.541193 4393846208 feedforward_robust.py:716] Epoch: 0055    cost: 2.262097307 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:12.543124 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0056    cost: 2.261967191 \n",
      "I0611 18:11:13.600036 4393846208 feedforward_robust.py:716] Epoch: 0056    cost: 2.261967191 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:13.601646 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0057    cost: 2.262014441 \n",
      "I0611 18:11:14.766727 4393846208 feedforward_robust.py:716] Epoch: 0057    cost: 2.262014441 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:14.768407 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0058    cost: 2.261990563 \n",
      "I0611 18:11:15.827133 4393846208 feedforward_robust.py:716] Epoch: 0058    cost: 2.261990563 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:15.829139 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0059    cost: 2.262043802 \n",
      "I0611 18:11:16.876168 4393846208 feedforward_robust.py:716] Epoch: 0059    cost: 2.262043802 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:16.878675 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0060    cost: 2.261977992 \n",
      "I0611 18:11:18.000371 4393846208 feedforward_robust.py:716] Epoch: 0060    cost: 2.261977992 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:18.004168 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0061    cost: 2.261840062 \n",
      "I0611 18:11:19.218397 4393846208 feedforward_robust.py:716] Epoch: 0061    cost: 2.261840062 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:19.220062 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0062    cost: 2.261906820 \n",
      "I0611 18:11:20.576148 4393846208 feedforward_robust.py:716] Epoch: 0062    cost: 2.261906820 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:20.577723 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0063    cost: 2.261878542 \n",
      "I0611 18:11:21.765487 4393846208 feedforward_robust.py:716] Epoch: 0063    cost: 2.261878542 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:21.766887 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0064    cost: 2.261875076 \n",
      "I0611 18:11:22.983222 4393846208 feedforward_robust.py:716] Epoch: 0064    cost: 2.261875076 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:22.984663 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0065    cost: 2.261832777 \n",
      "I0611 18:11:24.321419 4393846208 feedforward_robust.py:716] Epoch: 0065    cost: 2.261832777 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:24.323132 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0066    cost: 2.261841347 \n",
      "I0611 18:11:25.726904 4393846208 feedforward_robust.py:716] Epoch: 0066    cost: 2.261841347 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:25.728658 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0067    cost: 2.261756406 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 18:11:26.913780 4393846208 feedforward_robust.py:716] Epoch: 0067    cost: 2.261756406 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:26.915063 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0068    cost: 2.261788296 \n",
      "I0611 18:11:28.147523 4393846208 feedforward_robust.py:716] Epoch: 0068    cost: 2.261788296 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:28.149203 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0069    cost: 2.261773589 \n",
      "I0611 18:11:29.342586 4393846208 feedforward_robust.py:716] Epoch: 0069    cost: 2.261773589 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:29.343822 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0070    cost: 2.261727954 \n",
      "I0611 18:11:30.522279 4393846208 feedforward_robust.py:716] Epoch: 0070    cost: 2.261727954 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:30.523824 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0071    cost: 2.261739371 \n",
      "I0611 18:11:31.648666 4393846208 feedforward_robust.py:716] Epoch: 0071    cost: 2.261739371 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:31.651057 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0072    cost: 2.261627529 \n",
      "I0611 18:11:33.114961 4393846208 feedforward_robust.py:716] Epoch: 0072    cost: 2.261627529 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:33.116453 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0073    cost: 2.261710367 \n",
      "I0611 18:11:34.543848 4393846208 feedforward_robust.py:716] Epoch: 0073    cost: 2.261710367 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:34.545244 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0074    cost: 2.261646201 \n",
      "I0611 18:11:35.913261 4393846208 feedforward_robust.py:716] Epoch: 0074    cost: 2.261646201 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:35.915318 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0075    cost: 2.261648973 \n",
      "I0611 18:11:37.278047 4393846208 feedforward_robust.py:716] Epoch: 0075    cost: 2.261648973 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:37.279469 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0076    cost: 2.261545020 \n",
      "I0611 18:11:38.463598 4393846208 feedforward_robust.py:716] Epoch: 0076    cost: 2.261545020 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:38.464887 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0077    cost: 2.261483455 \n",
      "I0611 18:11:39.621922 4393846208 feedforward_robust.py:716] Epoch: 0077    cost: 2.261483455 \n",
      "Accuracy on batch: 0.906250\n",
      "I0611 18:11:39.627568 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.906250\n",
      "Epoch: 0078    cost: 2.261541187 \n",
      "I0611 18:11:40.785046 4393846208 feedforward_robust.py:716] Epoch: 0078    cost: 2.261541187 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:40.786636 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0079    cost: 2.261524091 \n",
      "I0611 18:11:41.945116 4393846208 feedforward_robust.py:716] Epoch: 0079    cost: 2.261524091 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:41.947450 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0080    cost: 2.261557974 \n",
      "I0611 18:11:43.236497 4393846208 feedforward_robust.py:716] Epoch: 0080    cost: 2.261557974 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:43.237930 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0081    cost: 2.261472060 \n",
      "I0611 18:11:44.622611 4393846208 feedforward_robust.py:716] Epoch: 0081    cost: 2.261472060 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:11:44.628023 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n",
      "Epoch: 0082    cost: 2.261501320 \n",
      "I0611 18:11:45.843258 4393846208 feedforward_robust.py:716] Epoch: 0082    cost: 2.261501320 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:45.852624 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0083    cost: 2.261452829 \n",
      "I0611 18:11:47.002139 4393846208 feedforward_robust.py:716] Epoch: 0083    cost: 2.261452829 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:47.003758 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0084    cost: 2.261466784 \n",
      "I0611 18:11:48.279051 4393846208 feedforward_robust.py:716] Epoch: 0084    cost: 2.261466784 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:48.281392 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0085    cost: 2.261417715 \n",
      "I0611 18:11:49.506254 4393846208 feedforward_robust.py:716] Epoch: 0085    cost: 2.261417715 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:49.512848 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0086    cost: 2.261301564 \n",
      "I0611 18:11:50.830712 4393846208 feedforward_robust.py:716] Epoch: 0086    cost: 2.261301564 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:50.834840 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0087    cost: 2.261414487 \n",
      "I0611 18:11:52.188764 4393846208 feedforward_robust.py:716] Epoch: 0087    cost: 2.261414487 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:52.190539 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0088    cost: 2.261273735 \n",
      "I0611 18:11:53.475656 4393846208 feedforward_robust.py:716] Epoch: 0088    cost: 2.261273735 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:53.477782 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0089    cost: 2.261310996 \n",
      "I0611 18:11:54.765394 4393846208 feedforward_robust.py:716] Epoch: 0089    cost: 2.261310996 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:54.767235 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0090    cost: 2.261458751 \n",
      "I0611 18:11:56.084460 4393846208 feedforward_robust.py:716] Epoch: 0090    cost: 2.261458751 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:56.086164 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0091    cost: 2.261219250 \n",
      "I0611 18:11:57.377485 4393846208 feedforward_robust.py:716] Epoch: 0091    cost: 2.261219250 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:11:57.379289 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0092    cost: 2.261302347 \n",
      "I0611 18:11:58.795172 4393846208 feedforward_robust.py:716] Epoch: 0092    cost: 2.261302347 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:11:58.799977 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0093    cost: 2.261227855 \n",
      "I0611 18:12:00.165978 4393846208 feedforward_robust.py:716] Epoch: 0093    cost: 2.261227855 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:12:00.168651 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0094    cost: 2.261276387 \n",
      "I0611 18:12:01.418491 4393846208 feedforward_robust.py:716] Epoch: 0094    cost: 2.261276387 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:12:01.419935 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0095    cost: 2.261221015 \n",
      "I0611 18:12:02.753737 4393846208 feedforward_robust.py:716] Epoch: 0095    cost: 2.261221015 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:12:02.759322 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0096    cost: 2.261126574 \n",
      "I0611 18:12:04.145483 4393846208 feedforward_robust.py:716] Epoch: 0096    cost: 2.261126574 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:12:04.146961 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0097    cost: 2.261247845 \n",
      "I0611 18:12:05.541637 4393846208 feedforward_robust.py:716] Epoch: 0097    cost: 2.261247845 \n",
      "Accuracy on batch: 1.000000\n",
      "I0611 18:12:05.543426 4393846208 feedforward_robust.py:717] Accuracy on batch: 1.000000\n",
      "Epoch: 0098    cost: 2.261100345 \n",
      "I0611 18:12:06.833475 4393846208 feedforward_robust.py:716] Epoch: 0098    cost: 2.261100345 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:12:06.835175 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0099    cost: 2.261294403 \n",
      "I0611 18:12:07.982207 4393846208 feedforward_robust.py:716] Epoch: 0099    cost: 2.261294403 \n",
      "Accuracy on batch: 0.968750\n",
      "I0611 18:12:07.983874 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.968750\n",
      "Epoch: 0100    cost: 2.261213974 \n",
      "I0611 18:12:09.184792 4393846208 feedforward_robust.py:716] Epoch: 0100    cost: 2.261213974 \n",
      "Accuracy on batch: 0.937500\n",
      "I0611 18:12:09.186619 4393846208 feedforward_robust.py:717] Accuracy on batch: 0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "I0611 18:12:09.188057 4393846208 feedforward_robust.py:718] Optimization Finished!\n",
      "Final Train Loss 2.261950\n",
      "I0611 18:12:09.515667 4393846208 feedforward_robust.py:726] Final Train Loss 2.261950\n",
      "Final Train Accuracy 0.950267:\n",
      "I0611 18:12:09.519152 4393846208 feedforward_robust.py:727] Final Train Accuracy 0.950267:\n",
      "Model was trained on benign data\n",
      "I0611 18:12:09.524866 4393846208 feedforward_robust.py:745] Model was trained on benign data\n",
      "Model was evaluated on benign data\n",
      "I0611 18:12:09.759393 4393846208 feedforward_robust.py:642] Model was evaluated on benign data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Weight norms ----\n",
      "[81.77506, 21.89681, 19.51775, 2.9443429]\n",
      "----Regular test accuracy and loss ----\n",
      "(1.7286503, 0.8634)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is being evaluated on FGSM data\n",
      "I0611 18:12:09.977263 4393846208 feedforward_robust.py:649] Model is being evaluated on FGSM data\n",
      "Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n",
      "I0611 18:12:10.006647 4393846208 feedforward_robust.py:651] Model is being evaluated on PGD points generated using 0.010000 learning rate and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----FGSM test accuracy and loss ----\n",
      "(2.1431105, 0.3622)\n",
      "iteration: 0\n",
      "loss 1.850557\n",
      "iteration: 1\n",
      "loss 1.930215\n",
      "iteration: 2\n",
      "loss 1.998748\n",
      "iteration: 3\n",
      "loss 2.051919\n",
      "iteration: 4\n",
      "loss 2.095126\n",
      "iteration: 5\n",
      "loss 2.130426\n",
      "iteration: 6\n",
      "loss 2.161141\n",
      "iteration: 7\n",
      "loss 2.185529\n",
      "iteration: 8\n",
      "loss 2.208078\n",
      "iteration: 9\n",
      "loss 2.228520\n",
      "iteration: 10\n",
      "loss 2.246605\n",
      "iteration: 11\n",
      "loss 2.262784\n",
      "iteration: 12\n",
      "loss 2.278572\n",
      "iteration: 13\n",
      "loss 2.293634\n",
      "iteration: 14\n",
      "loss 2.307968\n",
      "iteration: 15\n",
      "loss 2.322614\n",
      "iteration: 16\n",
      "loss 2.331178\n",
      "iteration: 17\n",
      "loss 2.345902\n",
      "iteration: 18\n",
      "loss 2.354377\n",
      "iteration: 19\n",
      "loss 2.364953\n",
      "iteration: 20\n",
      "loss 2.373450\n",
      "iteration: 21\n",
      "loss 2.382411\n",
      "iteration: 22\n",
      "loss 2.391316\n",
      "iteration: 23\n",
      "loss 2.397739\n",
      "iteration: 24\n",
      "loss 2.405911\n",
      "iteration: 25\n",
      "loss 2.411819\n",
      "iteration: 26\n",
      "loss 2.418280\n",
      "iteration: 27\n",
      "loss 2.424141\n",
      "iteration: 28\n",
      "loss 2.430579\n",
      "iteration: 29\n",
      "loss 2.436071\n",
      "iteration: 30\n",
      "loss 2.442919\n",
      "iteration: 31\n",
      "loss 2.446775\n",
      "iteration: 32\n",
      "loss 2.452252\n",
      "iteration: 33\n",
      "loss 2.455638\n",
      "iteration: 34\n",
      "loss 2.462595\n",
      "iteration: 35\n",
      "loss 2.465964\n",
      "iteration: 36\n",
      "loss 2.470687\n",
      "iteration: 37\n",
      "loss 2.474474\n",
      "iteration: 38\n",
      "loss 2.479331\n",
      "iteration: 39\n",
      "loss 2.482541\n",
      "iteration: 40\n",
      "loss 2.485911\n",
      "iteration: 41\n",
      "loss 2.489881\n",
      "iteration: 42\n",
      "loss 2.491804\n",
      "iteration: 43\n",
      "loss 2.496028\n",
      "iteration: 44\n",
      "loss 2.498418\n",
      "iteration: 45\n",
      "loss 2.501096\n",
      "iteration: 46\n",
      "loss 2.503343\n",
      "iteration: 47\n",
      "loss 2.507528\n",
      "iteration: 48\n",
      "loss 2.508865\n",
      "iteration: 49\n",
      "loss 2.512045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is to confirm that attack does not violate constraints\n",
      "I0611 18:12:18.463122 4393846208 feedforward_robust.py:496] This is to confirm that attack does not violate constraints\n",
      "Should be no more than eps\n",
      "I0611 18:12:18.466264 4393846208 feedforward_robust.py:497] Should be no more than eps\n",
      "0.10000005352730845\n",
      "I0611 18:12:18.565474 4393846208 feedforward_robust.py:498] 0.10000005352730845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----PGD test accuracy and loss ----\n",
      "(2.5120447, 0.2442)\n"
     ]
    }
   ],
   "source": [
    "#Setup - Dataset stuff\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "hidden_sizes = [64, 64, 32]\n",
    "dataset = ((x_train_master_flat, y_train_master), (x_test_flat, y_test))\n",
    "\n",
    "scope_name = \"teacher_student_fashion\"\n",
    "if not load_weights:\n",
    "    with tf.variable_scope(scope_name, reuse = False) as scope:\n",
    "\n",
    "        logdir = tensorboard_dir + str(counter)\n",
    "\n",
    "        #Create model\n",
    "        writer = tf.summary.FileWriter(logdir)\n",
    "        model = ffr.RobustMLP(input_shape, hidden_sizes, num_classes, writer = writer, scope = scope_name, logger = logger, sigma = sigma)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"Created model successfully. Now going to train\")\n",
    "    \n",
    "        #Train model\n",
    "        model.fit(sess, x_train_master_flat, y_train_master, training_epochs = epochs, reg_op = reg , lr = lr)\n",
    "        \n",
    "        \"\"\"\n",
    "        #Save weights\n",
    "        weights = tf.trainable_variables()\n",
    "        #weights = model.get_weights()[0] + model.get_weights()[1]\n",
    "        saver = tf.train.Saver(weights)\n",
    "        weights_path = saver.save(sess, weights_dir + \"model_\" + str(counter) + \".ckpt\")\n",
    "        print(\"Saved model at %s\"%weights_path)\n",
    "        \"\"\"\n",
    "        \n",
    "        weight_norms = model.get_weight_norms(sess)\n",
    "        print(\"----- Weight norms ----\")\n",
    "        print(weight_norms)\n",
    "        \n",
    "        #Test model - regular, fgsm adv, pgd adv\n",
    "        loss_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "        print(\"----Regular test accuracy and loss ----\")\n",
    "        print((loss_reg, acc_reg))\n",
    "        \n",
    "        loss_fgsm, acc_fgsm = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = False)\n",
    "        print(\"----FGSM test accuracy and loss ----\")\n",
    "        print((loss_fgsm, acc_fgsm))\n",
    "        \n",
    "        loss_pgd, acc_pgd = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = True, eta=pgd_eta, num_iter = pgd_num_iter)\n",
    "        print(\"----PGD test accuracy and loss ----\")\n",
    "        print((loss_pgd , acc_pgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for slave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(scope_name, reuse = False) as scope:\n",
    "        loss_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "        print(\"----Regular test accuracy and loss ----\")\n",
    "        print((loss_reg, acc_reg))\n",
    "        \n",
    "        z_train_slave = model.get_prediction(sess, x_train_slave_flat)\n",
    "        z_test_slave = model.get_prediction(sess, x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_slave[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train slave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup - Dataset stuff\n",
    "def slave_training():\n",
    "    epochs = 30\n",
    "    lr = 15e-4\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    hidden_sizes = [64, 64, 32]\n",
    "    dataset = ((x_train_slave_flat, z_train_slave), (x_test_flat, y_test))\n",
    "\n",
    "    scope_name = \"teacher_student_fashion\"\n",
    "    if not load_weights:\n",
    "        with tf.variable_scope(scope_name, reuse = tf.AUTO_REUSE) as scope:\n",
    "\n",
    "            logdir = tensorboard_dir + str(counter)\n",
    "\n",
    "            #Create model\n",
    "            writer = tf.summary.FileWriter(logdir)\n",
    "            model = ffr.RobustMLP(input_shape, hidden_sizes, num_classes, writer = writer, scope = scope_name, logger = logger, sigma = sigma, classification = False)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"Created model successfully. Now going to train\")\n",
    "\n",
    "            #Train model\n",
    "            model.fit(sess, x_train_slave_flat, z_train_slave, training_epochs = epochs, reg_op = reg , lr = lr)\n",
    "\n",
    "            \"\"\"\n",
    "            #Save weights\n",
    "            weights = tf.trainable_variables()\n",
    "            #weights = model.get_weights()[0] + model.get_weights()[1]\n",
    "            saver = tf.train.Saver(weights)\n",
    "            weights_path = saver.save(sess, weights_dir + \"model_\" + str(counter) + \".ckpt\")\n",
    "            print(\"Saved model at %s\"%weights_path)\n",
    "            \"\"\"\n",
    "            loss_real_train, acc_train = model.evaluate(sess, x_train_slave_flat, z_train_slave)\n",
    "\n",
    "            #Test model - regular, fgsm adv, pgd adv\n",
    "            loss_real_reg, acc_real_reg = model.evaluate(sess, x_test_flat, z_test_slave)\n",
    "            print(\"----Regular test loss and accuracy ----\")\n",
    "            print((loss_real_reg, acc_real_reg))\n",
    "            \n",
    "            loss_class_reg, acc_reg = model.evaluate(sess, x_test_flat, y_test)\n",
    "            print(\"----Real test loss and accuracy comparing to teacher ----\")\n",
    "            print((loss_class_reg, acc_reg))\n",
    "\n",
    "            loss_fgsm, acc_fgsm = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = False)\n",
    "            print(\"----FGSM test loss and accuracy ----\")\n",
    "            print((loss_fgsm, acc_fgsm))\n",
    "\n",
    "            loss_pgd, acc_pgd = model.adv_evaluate(sess, x_test_flat, y_test, eps_test, pgd = True, eta=pgd_eta, num_iter = pgd_num_iter)\n",
    "            print(\"----PGD test loss and accuracy ----\")\n",
    "            print((loss_pgd , acc_pgd))\n",
    "            \n",
    "            slave_train_confidences = model.get_prediction(sess, x_train_slave_flat)\n",
    "            slave_test_confidences = model.get_prediction(sess, x_test_flat)\n",
    "            \n",
    "            return loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg, slave_train_confidences, slave_test_confidences\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup = slave_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['mse on z_train'] = []\n",
    "df['acc on z_train'] = []\n",
    "df['mse on z_test'] = []\n",
    "df['acc on z_test'] = []\n",
    "df['acc on y_test'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_confidences = []\n",
    "test_confidences = []\n",
    "for i in range(3):\n",
    "    loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg, slave_train_confidences, slave_test_confidences = slave_training()\n",
    "    df.loc[i] = [loss_real_train, acc_train, loss_real_reg, acc_real_reg, acc_reg]\n",
    "    train_confidences.append(slave_train_confidences)\n",
    "    test_confidences.append(slave_test_confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"ts_fashion_results.xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
